{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcds/.conda/envs/llm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model /home/bcds/venv/dilab/Mixtral-8x7B-v0.1\n",
      "Set profile_threshold to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcds/On-the-Fly_MoE_Inference/expert_predictor/modeling_mixtral.py:87: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  up_th = torch.load(threshold_path, map_location='cuda')[\"up_proj_states_thresholds_2\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds loaded from /home/bcds/On-the-Fly_MoE_Inference/saving/threshold/c4_mixtral_up/thresholds_0_8.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 19/19 [00:20<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from modeling_mixtral import MixtralForCausalLM, set_profile_mode, load_thresholds\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,7\"\n",
    "\n",
    "def _load_model(model_name, threshold_path, device_map):\n",
    "    print(f\"Loading model {model_name}\")\n",
    "    ## 开启稀疏模式\n",
    "    set_profile_mode(False)\n",
    "    load_thresholds(f'{threshold_path}/thresholds_0_8.pt', use_average=True)\n",
    "\n",
    "    model = MixtralForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=device_map,\n",
    "        use_cache=True,\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    return model, tokenizer\n",
    "\n",
    "model_name = 'mixtral'\n",
    "threshold_path_name = 'chess_up_threshold'\n",
    "with open('../path.json', 'r') as f:\n",
    "    path = json.load(f)\n",
    "    model_name = path['mixtral']\n",
    "    threshold_path = path[threshold_path_name]\n",
    "\n",
    "with open('../quantize/device_map_1.json', 'r') as f:\n",
    "    device_map = json.load(f)\n",
    "model, tokenizer = _load_model(model_name, threshold_path, device_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1580875/954874683.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  datasets = torch.load('../saving/threshold/chess/datasets.pt')\n"
     ]
    }
   ],
   "source": [
    "datasets = torch.load('../saving/threshold/chess/datasets.pt')\n",
    "import torch\n",
    "import numpy as np\n",
    "def get_batch(data, batch_size, block_size):\n",
    "    start_idxs = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in start_idxs])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in start_idxs])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存激活值和专家路由的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "sparsity_level = 0.8\n",
    "# device = 'cuda:1'\n",
    "device_2 = 'cpu'\n",
    "avg_loss = 0.0\n",
    "n_batch = 64\n",
    "# n_batch = 2\n",
    "# accum_steps = 4 \n",
    "accum_steps = 2\n",
    "batch_size = 1\n",
    "block_size = 2048\n",
    "torch.manual_seed(42)\n",
    "n_layers = len(model.model.layers)\n",
    "n_experts = len(model.model.layers[0].block_sparse_moe.experts)\n",
    "split = 'train'\n",
    "\n",
    "with torch.no_grad():\n",
    "    # for step in range(n_batch // accum_steps):\n",
    "    for step in trange(n_batch // accum_steps):\n",
    "        # print(step * accum_steps)\n",
    "        for batch_idx in range(accum_steps):\n",
    "            # print('batch_idx:', batch_idx)\n",
    "            inputs, labels = get_batch(datasets[split], batch_size, block_size)\n",
    "            inputs = inputs.cuda()\n",
    "            outputs = model(inputs, labels=inputs)\n",
    "            avg_loss = avg_loss + outputs.loss / n_batch\n",
    "\n",
    "for layer_idx in range(1, n_layers):\n",
    "    d = list(zip(model.model.layers[layer_idx-1].block_sparse_moe.activations, model.model.layers[layer_idx].block_sparse_moe.gate_logits))\n",
    "    \n",
    "    torch.save(d,f'merge/a2ef_{layer_idx}.pth')\n",
    "    print(f'saving merge/a2ef_{layer_idx}.pth done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 专家预测器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast  # 用于混合精度训练\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "def top_k_position_accuracy_unordered(output, target, k=1):\n",
    "    \"\"\"Compute the accuracy based on the intersection of top-k values between output and target,\n",
    "       regardless of their order.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # 获取 output 和 target 中 top-k 最大值的索引\n",
    "        _, topk_pred_indices = output.topk(k, 1, True)\n",
    "        _, topk_target_indices = target.topk(k, 1, True)\n",
    "        # 初始化批次的正确计数\n",
    "        batch_size = output.size(0)\n",
    "        correct_counts = 0\n",
    "        \n",
    "        # 检查每个样本的预测top-k是否包含在真实的top-k中\n",
    "        for i in range(batch_size):\n",
    "            # 将预测和目标的top-k索引转换为集合\n",
    "            set_pred = set(topk_pred_indices[i].tolist())\n",
    "            set_target = set(topk_target_indices[i].tolist())\n",
    "            \n",
    "            # 计算交集\n",
    "            intersection = set_pred.intersection(set_target)\n",
    "            \n",
    "            # 计算正确的预测个数\n",
    "            correct_counts = correct_counts+len(intersection)\n",
    "        \n",
    "        # 计算平均正确率\n",
    "        return correct_counts,batch_size*k\n",
    "\n",
    "def eval_model(model, val_loader,):\n",
    "    # Example validation loop\n",
    "    model.eval()\n",
    "    total_topk_accuracy_1 = 0\n",
    "    total_topk_accuracy_2 = 0\n",
    "    cont=0\n",
    "    len1=0\n",
    "    len2=0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(\"cuda\"), targets.to(\"cuda\")\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "            # 计算 top-K 准确率（不考虑顺序）\n",
    "            topk_accuracy_1 = top_k_position_accuracy_unordered(outputs, targets, k=1)\n",
    "            topk_accuracy_2 = top_k_position_accuracy_unordered(outputs, targets, k=2)\n",
    "            total_topk_accuracy_1 += topk_accuracy_1[0]\n",
    "            total_topk_accuracy_2 += topk_accuracy_2[0]\n",
    "            len1+= topk_accuracy_1[1]\n",
    "            len2+= topk_accuracy_2[1]   \n",
    "        avg_topk_accuracy_1 = total_topk_accuracy_1 / len1\n",
    "        avg_topk_accuracy_2 = total_topk_accuracy_2 / len2\n",
    "        # print(len2)\n",
    "        print(f'Validation Top-{1} Position Accuracy (unordered): {avg_topk_accuracy_1:.4f}')\n",
    "        print(f'Validation Top-{2} Position Accuracy (unordered): {avg_topk_accuracy_2:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1645832/1446284515.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  file_data = torch.load(file_path)\n",
      "/tmp/ipykernel_1645832/2285657240.py:44: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Top-1 Position Accuracy (unordered): 0.8144\n",
      "Validation Top-2 Position Accuracy (unordered): 0.8049\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_paths):\n",
    "        # 加载数据\n",
    "        self.data = []\n",
    "        \n",
    "        # 遍历文件路径列表，加载每个文件\n",
    "        for file_path in file_paths:\n",
    "            # 加载当前文件的数据\n",
    "            file_data = torch.load(file_path)\n",
    "            # 将当前文件的数据追加到总数据列表中\n",
    "            self.data.extend(file_data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.data[idx]\n",
    "        return x.detach().clone(), y.detach().clone()\n",
    "\n",
    "\n",
    "for i in range(31, 32):\n",
    "    print(\"layer \", i)\n",
    "    dataset = CustomDataset(file_paths=[f'merge/a2ef_{i}.pth'])\n",
    "    # 划分训练集和验证集\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=2048, shuffle=False)\n",
    "\n",
    "    gate_router = model.model.layers[i].block_sparse_moe.gate\n",
    "    eval_model(gate_router, train_loader,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleLinearModel(\n",
       "  (linear1): Linear(in_features=4096, out_features=128, bias=True)\n",
       "  (activation): SiLU()\n",
       "  (linear2): Linear(in_features=128, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast  # 用于混合精度训练\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "class SimpleLinearModel(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim,hidden_dim=32):\n",
    "        super(SimpleLinearModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.activation = nn.SiLU() # 添加 ReLU 激活函数\n",
    "        self.linear2 = nn.Linear(hidden_dim,output_dim)  # 添加一个 8x8 线性层\n",
    "        init.kaiming_normal_(self.linear1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        init.kaiming_normal_(self.linear2.weight, mode='fan_out', nonlinearity='relu')\n",
    "        self.linear1.bias.data.fill_(0)\n",
    "        self.linear2.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.linear1(x)\n",
    "        x= self.activation(x)\n",
    "        return self.linear2(x)\n",
    "        \n",
    "model=SimpleLinearModel(4096,8, hidden_dim=128)\n",
    "model.to(\"cuda\")  # 假设使用 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=25):\n",
    "    scaler = GradScaler()  # 创建 GradScaler 对象\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 使用 autocast 来进行自动混合精度处理\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                # kl\n",
    "                outputs_probs = F.log_softmax(outputs, dim=1)\n",
    "                loss=criterion(outputs_probs, targets)\n",
    "                # mse\n",
    "                # loss = criterion(outputs, targets)\n",
    "\n",
    "            # 使用 GradScaler 来缩放损失，然后进行反向传播\n",
    "            # 注意：反向传播不包含在 autocast() 块中\n",
    "            scaler.scale(loss).backward()\n",
    "            writer.add_scalar('Loss/Train', loss.item(), epoch * len(train_loader) + batch_idx)\n",
    "            # 调用 scaler.step() 来更新模型权重，并调用 scaler.update() 准备下一步\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    # kl\n",
    "                    outputs_probs=F.log_softmax(outputs, dim=1)\n",
    "                    val_loss += criterion(outputs_probs, targets).item()\n",
    "                    # mse\n",
    "                    # val_loss += criterion(outputs, targets).item()\n",
    "            print(f'Epoch {epoch+1}, Validation Loss: {val_loss / len(val_loader)}')\n",
    "            \n",
    "# criterion = nn.MSELoss().to(\"cuda\")\n",
    "criterion = nn.KLDivLoss(reduction='batchmean').to(\"cuda\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.004) #lr=5e-5\n",
    "writer = SummaryWriter('runs/predictor_multilayer')\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
