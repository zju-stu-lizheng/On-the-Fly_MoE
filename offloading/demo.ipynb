{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 68.47it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 389.97it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RunTimeError' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/newdata/lz/on_the_fly_moe/offloading/demo.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewlab/mnt/newdata/lz/on_the_fly_moe/offloading/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# #Optimize\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bnewlab/mnt/newdata/lz/on_the_fly_moe/offloading/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhqq\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpatching\u001b[39;00m \u001b[39mimport\u001b[39;00m prepare_for_inference\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bnewlab/mnt/newdata/lz/on_the_fly_moe/offloading/demo.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m prepare_for_inference(llm, backend\u001b[39m=\u001b[39;49mbackend, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/moe/lib/python3.10/site-packages/hqq/utils/patching.py:122\u001b[0m, in \u001b[0;36mprepare_for_inference\u001b[0;34m(model, allow_merge, backend, verbose)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m backend \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbitblas\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    121\u001b[0m     \u001b[39mif\u001b[39;00m patch_hqq_to_bitblas \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m         \u001b[39mraise\u001b[39;00m RunTimeError(\u001b[39m'\u001b[39m\u001b[39mBitBlas backend is not available. Check if bitblas is correctly installed if you want to use the BitBlas backend (https://github.com/mobiusml/bitblas/).\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    123\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m         patch_linearlayers(model, patch_hqq_to_bitblas, verbose\u001b[39m=\u001b[39mverbose)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RunTimeError' is not defined"
     ]
    }
   ],
   "source": [
    "# OMP_NUM_THREADS=16 CUDA_VISIBLE_DEVICES=0 python demo.py \n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3, 4\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "from modeling_mixtral import MixtralForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "with open('../path.json', 'r') as f:\n",
    "    path = json.load(f)\n",
    "    model_name = path['mixtral']\n",
    "\n",
    "save_dir = './hqqsaved'\n",
    "backend       = \"bitblas\" #'torchao_int4' #\"torchao_int4\" (4-bit only) or \"gemlite\" (4-bit + 2-bit)\n",
    "dtype = torch.bfloat16 if backend==\"torchao_int4\" else torch.float16\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir='./')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "### HQQ量化\n",
    "from hqq.core.quantize import *\n",
    "from hqq.models.hf.mixtral import MixtralPatch\n",
    "import transformers\n",
    "from hqq.models.base import BaseHQQModel\n",
    "from accelerate import init_empty_weights\n",
    "\n",
    "class BaseHQQHFModel(BaseHQQModel):\n",
    "    # Save model architecture\n",
    "    @classmethod\n",
    "    def cache_model(cls, model, save_dir):\n",
    "        model.config.save_pretrained(save_dir)\n",
    "\n",
    "    # Create empty model from config\n",
    "    @classmethod\n",
    "    def create_model(cls, save_dir, kwargs):\n",
    "        model_kwargs = {}\n",
    "        for key in [\"attn_implementation\"]:\n",
    "            if key in kwargs:\n",
    "                model_kwargs[key] = kwargs[key]\n",
    "\n",
    "        config = transformers.AutoConfig.from_pretrained(\n",
    "            cls.get_config_file(save_dir)\n",
    "        )\n",
    "\n",
    "        with init_empty_weights():\n",
    "            model = MixtralForCausalLM._from_config(config, **model_kwargs)\n",
    "\n",
    "        return model\n",
    "\n",
    "class MixtralHQQ(MixtralPatch, BaseHQQHFModel):\n",
    "    pass\n",
    " \n",
    "\n",
    "llm = MixtralHQQ.from_quantized(save_dir, compute_dtype=dtype, device='cuda:0', use_cache=True)\n",
    "HQQLinear.set_backend(HQQBackend.PYTORCH)\n",
    "\n",
    "\n",
    "# #Optimize\n",
    "from hqq.utils.patching import prepare_for_inference\n",
    "prepare_for_inference(llm, backend=backend, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "input_length = 8\n",
    "MAX_LENGTH = input_length\n",
    "output_length = 16\n",
    "device_id = 0\n",
    "test_samples = 1\n",
    "\n",
    "def preprocess_data(data, tokenizer):\n",
    "\t# 使用 tokenizer 将文本数据转换为模型输入\n",
    "\tinputs = tokenizer(data, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
    "\tinputs[\"labels\"] = inputs.input_ids.clone()\n",
    "\treturn inputs\n",
    "\n",
    "generated_all, decode_time, prefill_time = 0, 0, 0\n",
    "# print(\"max output length is {}\".format(output_length))\n",
    "text = \"The future of AI is here, and \"\n",
    "\n",
    "inputs = preprocess_data(text, tokenizer)\n",
    "# # 测试时间\n",
    "# start_event = torch.cuda.Event(enable_timing=True)\n",
    "# end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "# 开始计时\n",
    "# torch.cuda.synchronize()\n",
    "# start_event.record()\n",
    "\n",
    "# 前向传播\n",
    "with torch.no_grad():\n",
    "    output = llm.generate(\n",
    "        input_ids=inputs[\"input_ids\"].cuda(device_id),\n",
    "        attention_mask=inputs[\"attention_mask\"].cuda(device_id),\n",
    "        max_length=input_length + output_length,  # 总长度为输入长度 + 输出长度\n",
    "        generation_config=GenerationConfig(do_sample=False),\n",
    "        pad_token_id=tokenizer.pad_token_id, \n",
    "        # cache_implementation=\"static\" ## moe not support\n",
    "    )\n",
    "\n",
    "# 结束计时\n",
    "# end_event.record()\n",
    "# torch.cuda.synchronize()\n",
    "\n",
    "# 计算时间\n",
    "# elapsed_time = start_event.elapsed_time(end_event) / 1000  # 转换为秒\n",
    "# decode_time += elapsed_time\n",
    "# print(f\"Generated length: {len(output[0]) - input_length}\", f\"Time taken: {elapsed_time:.2f} s\")\n",
    "# print(output)\n",
    "print(tokenizer.batch_decode(output, skip_special_tokens=True))\n",
    "\n",
    "# generated_all += (len(output[0]) - input_length -1)\n",
    "\n",
    "# timepertoken = (decode_time) / (generated_all)\n",
    "# print(\"decode phase speed:\", '{:.4f}'.format(1/timepertoken) , ' token/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先都加载到cpu上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcds/.conda/envs/llm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/bcds/venv/dilab/floe/hqq/hqq/models/base.py:251: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(cls.get_weight_file(save_dir), map_location=map_location)\n",
      "100%|██████████| 32/32 [00:00<00:00, 58.67it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 585.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3, 4\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "from modeling_mixtral import MixtralForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "with open('../path.json', 'r') as f:\n",
    "    path = json.load(f)\n",
    "    model_name = path['mixtral']\n",
    "    # threshold_path = path[threshold_path_name]\n",
    "\n",
    "with open(\"../quantize/device_map.json\", \"r\") as f:\n",
    "    device_map = json.load(f)\n",
    "\n",
    "dtype = torch.float16\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir='./')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "### HQQ量化\n",
    "from hqq.core.quantize import *\n",
    "from hqq.models.hf.mixtral import MixtralPatch\n",
    "import transformers\n",
    "from hqq.models.base import BaseHQQModel\n",
    "from accelerate import init_empty_weights\n",
    "\n",
    "class BaseHQQHFModel(BaseHQQModel):\n",
    "    # Save model architecture\n",
    "    @classmethod\n",
    "    def cache_model(cls, model, save_dir):\n",
    "        model.config.save_pretrained(save_dir)\n",
    "\n",
    "    # Create empty model from config\n",
    "    @classmethod\n",
    "    def create_model(cls, save_dir, kwargs):\n",
    "        model_kwargs = {}\n",
    "        for key in [\"attn_implementation\"]:\n",
    "            if key in kwargs:\n",
    "                model_kwargs[key] = kwargs[key]\n",
    "\n",
    "        config = transformers.AutoConfig.from_pretrained(\n",
    "            cls.get_config_file(save_dir)\n",
    "        )\n",
    "\n",
    "        with init_empty_weights():\n",
    "            model = MixtralForCausalLM._from_config(config, **model_kwargs)\n",
    "\n",
    "        return model\n",
    "\n",
    "class MixtralHQQ(MixtralPatch, BaseHQQHFModel):\n",
    "    pass\n",
    " \n",
    "save_dir = './hqq4'\n",
    "llm = MixtralHQQ.from_quantized(save_dir, compute_dtype=dtype, device='cuda:0', use_cache=True)\n",
    "HQQLinear.set_backend(HQQBackend.PYTORCH)\n",
    "\n",
    "# backend       = \"gemlite\" #'torchao_int4' #\"torchao_int4\" (4-bit only) or \"gemlite\" (4-bit + 2-bit)\n",
    "# # #Optimize\n",
    "# from hqq.utils.patching import prepare_for_inference\n",
    "# prepare_for_inference(llm, backend=backend, verbose=True)\n",
    "# # Load GemLite cache\n",
    "# if(backend == 'gemlite'):\n",
    "# \timport gemlite\n",
    "# \tgemlite.core.GEMLITE_TRITON_RESTRICT_M = True\n",
    "# \tgemlite.core.GemLiteLinear.load_config('/tmp/gemlite_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0503, device='cuda:0', dtype=torch.float16)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Outputs do not match",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/bcds/On-the-Fly_MoE_Inference/offloading/demo.ipynb 单元格 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bh100/home/bcds/On-the-Fly_MoE_Inference/offloading/demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m random\u001b[39m.\u001b[39mseed(\u001b[39m42\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bh100/home/bcds/On-the-Fly_MoE_Inference/offloading/demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((\u001b[39m1\u001b[39m, in_features), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat16, device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m10.\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bh100/home/bcds/On-the-Fly_MoE_Inference/offloading/demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m check_valid(x, W, gemlite_linear)\n",
      "\u001b[1;32m/home/bcds/On-the-Fly_MoE_Inference/offloading/demo.ipynb 单元格 3\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bh100/home/bcds/On-the-Fly_MoE_Inference/offloading/demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# print(y_q)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bh100/home/bcds/On-the-Fly_MoE_Inference/offloading/demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m((y_ref \u001b[39m-\u001b[39m y_q)\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mmean())\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bh100/home/bcds/On-the-Fly_MoE_Inference/offloading/demo.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39massert\u001b[39;00m (y_ref \u001b[39m-\u001b[39m y_q)\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mmean() \u001b[39m<\u001b[39m tol, \u001b[39m'\u001b[39m\u001b[39mOutputs do not match\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Outputs do not match"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "def check_valid(x, W, quant_linear, tol=1e-3):\n",
    "    y_ref = torch.matmul(x, W.T)\n",
    "    # print(y_ref)\n",
    "    y_q   = quant_linear(x)\n",
    "    # print(y_q)\n",
    "    print((y_ref - y_q).abs().mean())\n",
    "    assert (y_ref - y_q).abs().mean() < tol, 'Outputs do not match'\n",
    "\n",
    "############################################################################################\n",
    "from hqq.core.quantize import HQQLinear, BaseQuantizeConfig\n",
    "\n",
    "in_features, out_features = 4096*4, 4096*2\n",
    "#W_nbits, group_size = 8, in_features \n",
    "W_nbits, group_size = 2, 128 \n",
    "#W_nbits, group_size = 2, 128\n",
    "\n",
    "linear       = torch.nn.Linear(in_features=in_features, out_features=out_features, bias=False, device='cuda:0')\n",
    "quant_config = BaseQuantizeConfig(nbits=W_nbits, group_size=group_size, quant_zero=False, quant_scale=False, axis=1)\n",
    "hqq_layer    = HQQLinear(linear, quant_config=quant_config, compute_dtype=torch.float16, device='cuda:0', del_orig=False) \n",
    "\n",
    "orig_shape   = (out_features, in_features)\n",
    "W            = hqq_layer.dequantize().reshape(orig_shape).to(torch.float16)\n",
    "############################################################################################\n",
    "\n",
    "from gemlite.core import GemLiteLinearTriton, DType\n",
    "gemlite_linear = GemLiteLinearTriton(W_nbits, \n",
    "                                    group_size=group_size, \n",
    "                                    in_features=in_features, \n",
    "                                    out_features=out_features, \n",
    "                                    input_dtype=DType.FP16, \n",
    "                                    output_dtype=DType.FP16)\n",
    "\n",
    "W_q           = hqq_layer.unpack(dtype=torch.uint8).view(orig_shape)\n",
    "scales        = hqq_layer.meta['scale']\n",
    "zeros         = hqq_layer.meta['zero']\n",
    "gemlite_linear.pack(W_q, scales, zeros, None)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "x = torch.randn((1, in_features), dtype=torch.float16, device='cuda:0')/10.\n",
    "\n",
    "check_valid(x, W, gemlite_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_compile(model):\n",
    "    # model.config.use_cache = True\n",
    "    # model.generation_config.cache_implementation = \"static\"\n",
    "    # model.eval()\n",
    "    \n",
    "    torch._dynamo.config.inline_inbuilt_nn_modules = False #torch 2.5.0 fix\n",
    "\n",
    "    forward_compiled = torch.compile(\n",
    "        model.forward, mode=\"reduce-overhead\", fullgraph=True\n",
    "    )\n",
    "\n",
    "    model.forward = forward_compiled\n",
    "\n",
    "### cuda graph is empty ???\n",
    "for i in range(len(llm.model.layers)):\n",
    "    for j in range(len(llm.model.layers[0].block_sparse_moe.experts)):\n",
    "        prepare_for_compile(llm.model.layers[i].block_sparse_moe.experts[j].w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "input_length = 1\n",
    "MAX_LENGTH = input_length\n",
    "output_length = 32\n",
    "device_id = 0\n",
    "test_samples = 1\n",
    "\n",
    "def preprocess_data(data, tokenizer):\n",
    "\t# 使用 tokenizer 将文本数据转换为模型输入\n",
    "\tinputs = tokenizer(data, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
    "\tinputs[\"labels\"] = inputs.input_ids.clone()\n",
    "\treturn inputs\n",
    "\n",
    "generated_all, decode_time, prefill_time = 0, 0, 0\n",
    "# print(\"max output length is {}\".format(output_length))\n",
    "text = \"The future of AI is here, and \"\n",
    "\n",
    "inputs = preprocess_data(text, tokenizer)\n",
    "\n",
    "# 前向传播\n",
    "for i in range(2):\n",
    "    with torch.no_grad():\n",
    "        output = llm.generate(\n",
    "            input_ids=inputs[\"input_ids\"].cuda(device_id),\n",
    "            attention_mask=inputs[\"attention_mask\"].cuda(device_id),\n",
    "            max_length=input_length + output_length,  # 总长度为输入长度 + 输出长度\n",
    "            generation_config=GenerationConfig(do_sample=False),\n",
    "            pad_token_id=tokenizer.pad_token_id, \n",
    "            # cache_implementation=\"static\" ## moe not support\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试一个正常输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "input_length = 8\n",
    "MAX_LENGTH = input_length\n",
    "output_length = 16\n",
    "device_id = 0\n",
    "test_samples = 1\n",
    "\n",
    "def preprocess_data(data, tokenizer):\n",
    "\t# 使用 tokenizer 将文本数据转换为模型输入\n",
    "\tinputs = tokenizer(data, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
    "\tinputs[\"labels\"] = inputs.input_ids.clone()\n",
    "\treturn inputs\n",
    "\n",
    "generated_all, decode_time, prefill_time = 0, 0, 0\n",
    "# print(\"max output length is {}\".format(output_length))\n",
    "text = \"The future of AI is here, and \"\n",
    "\n",
    "inputs = preprocess_data(text, tokenizer)\n",
    "# # 测试时间\n",
    "# start_event = torch.cuda.Event(enable_timing=True)\n",
    "# end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "# 开始计时\n",
    "# torch.cuda.synchronize()\n",
    "# start_event.record()\n",
    "\n",
    "# 前向传播\n",
    "with torch.no_grad():\n",
    "    output = llm.generate(\n",
    "        input_ids=inputs[\"input_ids\"].cuda(device_id),\n",
    "        attention_mask=inputs[\"attention_mask\"].cuda(device_id),\n",
    "        max_length=input_length + output_length,  # 总长度为输入长度 + 输出长度\n",
    "        generation_config=GenerationConfig(do_sample=False),\n",
    "        pad_token_id=tokenizer.pad_token_id, \n",
    "        # cache_implementation=\"static\" ## moe not support\n",
    "    )\n",
    "\n",
    "# 结束计时\n",
    "# end_event.record()\n",
    "# torch.cuda.synchronize()\n",
    "\n",
    "# 计算时间\n",
    "# elapsed_time = start_event.elapsed_time(end_event) / 1000  # 转换为秒\n",
    "# decode_time += elapsed_time\n",
    "# print(f\"Generated length: {len(output[0]) - input_length}\", f\"Time taken: {elapsed_time:.2f} s\")\n",
    "# print(output)\n",
    "print(tokenizer.batch_decode(output, skip_special_tokens=True))\n",
    "\n",
    "# generated_all += (len(output[0]) - input_length -1)\n",
    "\n",
    "# timepertoken = (decode_time) / (generated_all)\n",
    "# print(\"decode phase speed:\", '{:.4f}'.format(1/timepertoken) , ' token/s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output length is 20\n",
      "['How do you get HIV?\\nHIV can be passed on when infected bodily fluid, such as blood or semen, is passed into an un']\n",
      "[\"How do you get HIV?\\nHIV can be passed on when infected bodily fluid, such as blood or semen, is passed into an uninfected person's bloodstream. The main way the HIV virus is transmitted is by\"]\n",
      "['CTComms sends on average 2 million emails monthly on behalf of over 125 different charities and not for profits.\\nTake the complexity']\n",
      "['CTComms sends on average 2 million emails monthly on behalf of over 125 different charities and not for profits.\\nTake the complexity of working with a CRM system, add on top of that the use of A/B split']\n",
      "[\"Hold the salt: UCLA engineers develop revolutionary new desalination membrane\\nProcess uses atmospheric pressure plasma to create filtering 'brush\"]\n",
      "[\"Hold the salt: UCLA engineers develop revolutionary new desalination membrane\\nProcess uses atmospheric pressure plasma to create filtering 'brush'\\n\\nLos Angeles – What if you could squeeze as much fresh water as possible out of\"]\n",
      "[\"Not Just for Kids\\nThe Hunt for Falling Leaves...\\nNature's Color on the Ground\\nby Mary Catherine Ball\\nBeing a\"]\n",
      "[\"Not Just for Kids\\nThe Hunt for Falling Leaves...\\nNature's Color on the Ground\\nby Mary Catherine Ball\\nBeing a nature photographer is not just a childhood passion. There is something about colors from the earth that evoke\"]\n",
      "['The Solar and Heliospheric Observatory (SOHO) spacecraft is expected to discover its 1,000TH comet this summer']\n",
      "['The Solar and Heliospheric Observatory (SOHO) spacecraft is expected to discover its 1,000TH comet this summer, according to NASA.\\n\\nSOHO was deployed into interstellar space over two decades ago']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import GenerationConfig\n",
    "from gemlite.helper import A16Wn\n",
    "\n",
    "input_length = 32\n",
    "MAX_LENGTH = input_length\n",
    "output_length = 20\n",
    "test_samples = 5\n",
    "device_id = 0\n",
    "\n",
    "with open(\"../path.json\", \"r\") as f:\n",
    "    paths = json.load(f)\n",
    "    fineweb_path = paths[\"fineweb\"]\n",
    "\n",
    "def preprocess_data(data, tokenizer):\n",
    "\t# 使用 tokenizer 将文本数据转换为模型输入\n",
    "\tinputs = tokenizer(data, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
    "\tinputs[\"labels\"] = inputs.input_ids.clone()\n",
    "\treturn inputs\n",
    "\n",
    "filt_type = fineweb_path.split('.')[-1]\n",
    "fineweb = load_dataset(filt_type, data_files=fineweb_path) #726000\n",
    "fineweb_text = fineweb['train']['text']\n",
    "\n",
    "# 预热（避免第一次运行时的额外开销）\n",
    "# for text in fineweb_text[:5] :\n",
    "#     inputs = preprocess_data(text, tokenizer)\n",
    "#     with torch.no_grad():\n",
    "#         output = llm(input_ids=inputs[\"input_ids\"].cuda(device_id), attention_mask=inputs[\"attention_mask\"].cuda(device_id))\n",
    "\n",
    "generated_all = 0\n",
    "prefill_time, decode_time = 0, 0\n",
    "reloaded_experts = 0\n",
    "print(\"output length is {}\".format(output_length))\n",
    "for text in fineweb_text[2:2+test_samples] :\n",
    "    inputs = preprocess_data(text, tokenizer)\n",
    "\n",
    "    # # 测试时间\n",
    "    # start_event = torch.cuda.Event(enable_timing=True)\n",
    "    # end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    # # 开始计时\n",
    "    # torch.cuda.synchronize()\n",
    "    # start_event.record()\n",
    "    print(tokenizer.batch_decode(inputs[\"input_ids\"], skip_special_tokens=True))\n",
    "    # 前向传播\n",
    "    with torch.no_grad():\n",
    "        output = llm.generate(\n",
    "            input_ids=inputs[\"input_ids\"].cuda(device_id),\n",
    "            attention_mask=inputs[\"attention_mask\"].cuda(device_id),\n",
    "            max_length=input_length + output_length,  # 总长度为输入长度 + 输出长度\n",
    "            generation_config=GenerationConfig(do_sample=True),\n",
    "            pad_token_id=tokenizer.pad_token_id, \n",
    "            # cache_implementation=\"static\" ## moe not support\n",
    "        )\n",
    "\n",
    "    # 结束计时\n",
    "    # end_event.record()\n",
    "    # torch.cuda.synchronize()\n",
    "\n",
    "    # # 计算时间\n",
    "    # elapsed_time = start_event.elapsed_time(end_event) / 1000  # 转换为秒\n",
    "    # decode_time += elapsed_time\n",
    "    # print(f\"Generated length: {len(output[0]) - input_length}\", f\"Time taken: {elapsed_time:.2f} s,\")\n",
    "    # print(output)\n",
    "    print(tokenizer.batch_decode(output, skip_special_tokens=True))\n",
    "\n",
    "    # generated_all += (len(output[0]) - input_length - 1)\n",
    "\n",
    "# timepertoken = (decode_time) / (generated_all)\n",
    "# print(\"decode phase speed:\", '{:.4f}'.format(1/timepertoken) , 'token/s')\n",
    "# print(\"the number of reloaded experts per token:\", '{:.3f}'.format(reloaded_experts / generated_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output length is 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcds/.conda/envs/llm/lib/python3.9/site-packages/torch/cuda/graphs.py:84: UserWarning: The CUDA Graph is empty. This usually means that the graph was attempted to be captured on wrong device or stream. (Triggered internally at ../aten/src/ATen/cuda/CUDAGraph.cpp:208.)\n",
      "  super().capture_end()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                  Torch-Compiled Region        77.45%        2.833s        78.41%        2.869s       5.603ms       3.038ms         5.41%      16.160ms      31.563us           512  \n",
      "                       Scheduler.codegen (dynamo_timed)         9.00%     329.124ms         9.00%     329.124ms     164.562ms       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                        compile_fx_inner (dynamo_timed)         2.89%     105.613ms        12.73%     465.645ms     232.822ms       0.000us         0.00%       0.000us       0.000us             2  \n",
      "    compile_fx.<locals>.fw_compiler_base (dynamo_timed)         1.76%      64.536ms        15.10%     552.321ms     276.160ms       0.000us         0.00%      91.675us      45.838us             2  \n",
      "                  _compile.compile_inner (dynamo_timed)         1.50%      55.000ms        17.91%     655.166ms     327.583ms       0.000us         0.00%      91.675us      45.838us             2  \n",
      "                                       cudaLaunchKernel         0.78%      28.426ms         0.78%      28.426ms       3.535us       0.000us         0.00%       0.000us       0.000us          8041  \n",
      "          create_aot_dispatcher_function (dynamo_timed)         0.44%      16.238ms        16.04%     587.012ms     293.506ms       0.000us         0.00%      91.675us      45.838us             2  \n",
      "                                            aten::empty         0.39%      14.257ms         0.45%      16.485ms      15.493us       0.000us         0.00%       0.000us       0.000us          1064  \n",
      "                                               aten::mm         0.36%      12.993ms         0.49%      18.000ms      13.373us      17.978ms        32.02%      17.978ms      13.357us          1346  \n",
      "                                          aten::nonzero         0.33%      11.984ms         0.95%      34.775ms      67.919us       5.817ms        10.36%       7.343ms      14.343us           512  \n",
      "                                        cudaMemcpyAsync         0.32%      11.884ms         0.32%      11.884ms       5.286us       0.000us         0.00%       0.000us       0.000us          2248  \n",
      "         GraphLowering.compile_to_module (dynamo_timed)         0.31%      11.186ms         9.40%     343.756ms     171.878ms       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                                       aten::lift_fresh         0.30%      10.802ms         0.34%      12.459ms     120.956us       0.000us         0.00%      53.788us       0.522us           103  \n",
      "                                             aten::view         0.27%       9.847ms         0.32%      11.656ms       3.769us       0.000us         0.00%       0.000us       0.000us          3093  \n",
      "                           cudaStreamCreateWithPriority         0.24%       8.814ms         0.24%       8.814ms      68.859us       0.000us         0.00%       0.000us       0.000us           128  \n",
      "                                            aten::index         0.21%       7.674ms         0.34%      12.355ms      10.697us       1.790ms         3.19%       1.790ms       1.550us          1155  \n",
      "                                            aten::copy_         0.20%       7.424ms         0.55%      20.299ms       6.353us      14.214ms        25.31%      14.214ms       4.449us          3195  \n",
      "          OutputGraph.call_user_compiler (dynamo_timed)         0.20%       7.312ms        16.25%     594.639ms     297.320ms       0.000us         0.00%      91.675us      45.838us             2  \n",
      "                               TorchDynamo Cache Lookup         0.18%       6.544ms         0.18%       6.544ms      12.707us       0.000us         0.00%       0.000us       0.000us           515  \n",
      "                                              aten::mul         0.17%       6.337ms         0.24%       8.909ms       5.770us       2.646ms         4.71%       2.646ms       1.714us          1544  \n",
      "                       GraphLowering.run (dynamo_timed)         0.17%       6.324ms         0.25%       9.117ms       4.558ms       0.000us         0.00%       0.000us       0.000us             2  \n",
      "gemlite::gemv_revsplitK_A16fWnO16f_int32packing_forw...         0.14%       5.217ms         0.21%       7.543ms     471.422us      23.904us         0.04%      26.400us       1.650us            16  \n",
      "                                  cudaStreamSynchronize         0.14%       5.191ms         0.14%       5.191ms       9.489us       0.000us         0.00%       0.000us       0.000us           547  \n",
      "                                          aten::squeeze         0.14%       4.948ms         0.22%       8.091ms     505.698us       0.000us         0.00%       0.000us       0.000us            16  \n",
      "                                       aten::as_strided         0.13%       4.666ms         0.13%       4.731ms       0.598us       0.000us         0.00%       0.000us       0.000us          7910  \n",
      "                                    aten::empty_strided         0.12%       4.445ms         0.13%       4.737ms       5.777us       0.000us         0.00%       0.000us       0.000us           820  \n",
      "                                       aten::index_add_         0.08%       2.928ms         0.14%       5.024ms       9.812us       1.316ms         2.34%       1.316ms       2.570us           512  \n",
      "                                            aten::fill_         0.08%       2.879ms         0.19%       6.770ms       5.782us       2.598ms         4.63%       2.598ms       2.219us          1171  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.07%       2.408ms         0.07%       2.408ms       3.745us       0.000us         0.00%       0.000us       0.000us           643  \n",
      "                                              aten::add         0.06%       2.372ms         0.11%       3.971ms       8.708us       1.187ms         2.11%       1.187ms       2.602us           456  \n",
      "                                   aten::_foreach_copy_         0.06%       2.236ms         0.38%      14.042ms      27.534us       0.000us         0.00%      10.808ms      21.193us           510  \n",
      "                                            aten::slice         0.06%       2.182ms         0.11%       3.988ms       3.495us       0.000us         0.00%       0.000us       0.000us          1141  \n",
      "                 WrapperCodeGen.generate (dynamo_timed)         0.06%       2.091ms         0.06%       2.091ms       1.046ms       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                                            aten::clone         0.05%       1.975ms         0.28%      10.148ms      13.978us       0.000us         0.00%       2.037ms       2.806us           726  \n",
      "                                             aten::silu         0.05%       1.957ms         0.07%       2.491ms       4.865us     422.659us         0.75%     422.659us       0.826us           512  \n",
      "                                                 detach         0.05%       1.942ms         0.07%       2.408ms      19.417us       0.000us         0.00%       0.000us       0.000us           124  \n",
      "                                        aten::unsqueeze         0.05%       1.833ms         0.06%       2.205ms       1.624us       0.000us         0.00%       0.000us       0.000us          1358  \n",
      "                                           aten::select         0.05%       1.758ms         0.06%       2.246ms       1.455us       0.000us         0.00%       0.000us       0.000us          1543  \n",
      "                                                aten::t         0.05%       1.737ms         0.10%       3.588ms       1.931us       0.000us         0.00%       0.000us       0.000us          1858  \n",
      "                                           aten::matmul         0.05%       1.694ms         0.62%      22.536ms      15.289us       0.000us         0.00%      18.392ms      12.477us          1474  \n",
      "                                          aten::reshape         0.05%       1.653ms         0.14%       5.170ms       1.749us       0.000us         0.00%     432.707us       0.146us          2955  \n",
      "                                        cudaGraphLaunch         0.04%       1.637ms         0.04%       1.637ms       3.211us       0.000us         0.00%       0.000us       0.000us           510  \n",
      "                                             cudaMalloc         0.04%       1.571ms         0.04%       1.571ms     392.761us       0.000us         0.00%       0.000us       0.000us             4  \n",
      "                                        aten::transpose         0.04%       1.449ms         0.06%       2.319ms       1.065us       0.000us         0.00%       0.000us       0.000us          2178  \n",
      "                                              aten::cat         0.04%       1.358ms         0.06%       2.092ms      10.674us     801.094us         1.43%     801.094us       4.087us           196  \n",
      "                      Scheduler.__init__ (dynamo_timed)         0.04%       1.355ms         0.04%       1.355ms     677.567us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                                           aten::linear         0.04%       1.339ms         0.65%      23.727ms      17.628us       0.000us         0.00%      17.978ms      13.357us          1346  \n",
      "                                              aten::bmm         0.04%       1.333ms         0.05%       1.804ms      14.096us     413.192us         0.74%     413.192us       3.228us           128  \n",
      "                                    cudaLaunchKernelExC         0.03%       1.203ms         0.03%       1.203ms       4.663us       0.000us         0.00%       0.000us       0.000us           258  \n",
      "                                             aten::mean         0.03%       1.179ms         0.05%       1.666ms      12.812us     689.895us         1.23%     689.895us       5.307us           130  \n",
      "                                               aten::to         0.03%       1.145ms         0.18%       6.488ms       5.275us       0.000us         0.00%       1.344ms       1.093us          1230  \n",
      "                                            aten::zero_         0.03%       1.082ms         0.05%       1.910ms      13.643us       0.000us         0.00%     282.208us       2.016us           140  \n",
      "                                             aten::set_         0.03%       1.053ms         0.03%       1.053ms       1.854us       0.000us         0.00%       0.000us       0.000us           568  \n",
      "                                           aten::unbind         0.03%       1.015ms         0.06%       2.018ms       3.942us       0.000us         0.00%       0.000us       0.000us           512  \n",
      "                                              aten::pow         0.03%       1.001ms         0.04%       1.547ms      11.899us     311.625us         0.55%     311.625us       2.397us           130  \n",
      "                                         aten::randperm         0.03%     954.385us         0.04%       1.496ms     299.193us       0.000us         0.00%       0.000us       0.000us             5  \n",
      "                                             aten::topk         0.03%     923.914us         0.11%       3.897ms      60.886us     821.132us         1.46%     821.132us      12.830us            64  \n",
      "                                         aten::_to_copy         0.02%     910.569us         0.15%       5.343ms      12.751us       0.000us         0.00%       1.344ms       3.209us           419  \n",
      "                                  cudaFuncGetAttributes         0.02%     827.632us         0.02%     827.632us       2.570us       0.000us         0.00%       0.000us       0.000us           322  \n",
      "                                       aten::empty_like         0.02%     809.679us         0.07%       2.726ms       4.143us       0.000us         0.00%       0.000us       0.000us           658  \n",
      "                                         aten::_softmax         0.02%     721.926us         0.03%       1.185ms       9.257us     322.434us         0.57%     322.434us       2.519us           128  \n",
      "                                              aten::neg         0.02%     717.590us         0.03%       1.151ms       8.995us     457.483us         0.81%     457.483us       3.574us           128  \n",
      "                                        cudaMemsetAsync         0.02%     716.705us         0.02%     716.705us       5.513us       0.000us         0.00%       0.000us       0.000us           130  \n",
      "                                    aten::nonzero_numpy         0.02%     683.616us         1.02%      37.476ms      73.196us       0.000us         0.00%       7.343ms      14.343us           512  \n",
      "                                        aten::index_put         0.02%     660.927us         0.04%       1.438ms     479.172us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                            aten::rsqrt         0.02%     659.860us         0.03%       1.095ms       8.425us     321.533us         0.57%     321.533us       2.473us           130  \n",
      "                                              aten::sum         0.01%     519.726us         0.02%     753.354us      11.771us     277.191us         0.49%     277.191us       4.331us            64  \n",
      "                                  cudaStreamIsCapturing         0.01%     489.460us         0.01%     489.460us       0.463us       0.000us         0.00%       0.000us       0.000us          1057  \n",
      "                                          aten::resize_         0.01%     482.905us         0.01%     482.905us       0.932us       0.000us         0.00%       0.000us       0.000us           518  \n",
      "                                              aten::div         0.01%     473.122us         0.02%     722.343us      11.287us     153.260us         0.27%     153.260us       2.395us            64  \n",
      "                                         aten::scatter_         0.01%     465.536us         0.02%     741.771us      11.590us     188.967us         0.34%     188.967us       2.953us            64  \n",
      "                                           aten::detach         0.01%     408.802us         0.08%       3.046ms       6.846us       0.000us         0.00%       0.000us       0.000us           445  \n",
      "                                           aten::expand         0.01%     404.391us         0.01%     509.544us       1.320us       0.000us         0.00%       0.000us       0.000us           386  \n",
      "                                        aten::new_empty         0.01%     375.381us         0.01%     436.146us     109.036us       0.000us         0.00%       0.000us       0.000us             4  \n",
      "                                               cudaFree         0.01%     374.886us         0.01%     374.886us     374.886us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                       aten::contiguous         0.01%     373.304us         0.19%       7.131ms      13.928us       0.000us         0.00%       1.526ms       2.981us           512  \n",
      "                                          aten::detach_         0.01%     372.704us         0.01%     397.512us       7.500us       0.000us         0.00%       0.000us       0.000us            53  \n",
      "                            cudagraphify (dynamo_timed)         0.01%     369.909us         0.01%     442.475us     221.238us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                          cudaGraphInstantiateWithFlags         0.01%     352.119us         0.01%     352.119us     117.373us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                             aten::div_         0.01%     350.962us         0.02%     578.069us       9.032us     185.959us         0.33%     185.959us       2.906us            64  \n",
      "                                 cudaDeviceGetAttribute         0.01%     315.687us         0.01%     315.687us       0.409us       0.000us         0.00%       0.000us       0.000us           771  \n",
      "                                          aten::softmax         0.01%     307.454us         0.04%       1.492ms      11.659us       0.000us         0.00%     322.434us       2.519us           128  \n",
      "                                            aten::where         0.01%     304.299us         1.03%      37.781ms      73.790us       0.000us         0.00%       7.343ms      14.343us           512  \n",
      "                                    cudaPeekAtLastError         0.01%     298.892us         0.01%     298.892us       0.097us       0.000us         0.00%       0.000us       0.000us          3084  \n",
      "                                     aten::_unsafe_view         0.01%     288.119us         0.01%     288.119us       0.561us       0.000us         0.00%       0.000us       0.000us           514  \n",
      "                                   cudaFuncSetAttribute         0.01%     279.361us         0.01%     279.361us       0.539us       0.000us         0.00%       0.000us       0.000us           518  \n",
      "                      aten::_debug_has_internal_overlap         0.01%     273.946us         0.01%     273.946us      34.243us       0.000us         0.00%       0.000us       0.000us             8  \n",
      "                                  cudaDeviceSynchronize         0.01%     262.532us         0.01%     262.532us      17.502us       0.000us         0.00%       0.000us       0.000us            15  \n",
      "                                          aten::one_hot         0.01%     196.297us         0.05%       1.733ms      27.077us       0.000us         0.00%     328.167us       5.128us            64  \n",
      "                                            aten::zeros         0.01%     189.752us         0.04%       1.515ms      11.834us       0.000us         0.00%     279.712us       2.185us           128  \n",
      "                       mkldnn::_is_mkldnn_acl_supported         0.00%     182.113us         0.00%     182.113us     182.113us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                         prims::view_of         0.00%     156.576us         0.01%     225.995us      28.249us       0.000us         0.00%       0.000us       0.000us             8  \n",
      "                                        aten::index_add         0.00%     133.691us         0.02%     900.486us     900.486us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                          aten::permute         0.00%     127.257us         0.00%     146.265us       2.285us       0.000us         0.00%       0.000us       0.000us            64  \n",
      "                                      prims::as_strided         0.00%      93.462us         0.00%     125.717us      41.906us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                               aten::eq         0.00%      82.151us         0.00%     152.640us      16.960us      21.217us         0.04%      21.217us       2.357us             9  \n",
      "                                        cudaEventRecord         0.00%      74.562us         0.00%      74.562us       6.778us       0.000us         0.00%       0.000us       0.000us            11  \n",
      "                                   cudaDriverGetVersion         0.00%      57.249us         0.00%      57.249us       0.112us       0.000us         0.00%       0.000us       0.000us           513  \n",
      "                                      aten::result_type         0.00%      56.902us         0.00%      56.902us       0.438us       0.000us         0.00%       0.000us       0.000us           130  \n",
      "                                           aten::cumsum         0.00%      56.606us         0.00%     108.757us      36.252us      15.617us         0.03%      15.617us       5.206us             3  \n",
      "                                             aten::isin         0.00%      53.090us         0.01%     267.085us      89.028us       0.000us         0.00%      28.031us       9.344us             3  \n",
      "                                              aten::sub         0.00%      52.595us         0.00%      83.402us      11.915us      16.545us         0.03%      16.545us       2.364us             7  \n",
      "                                   aten::_reshape_alias         0.00%      50.877us         0.00%      50.877us       1.590us       0.000us         0.00%       0.000us       0.000us            32  \n",
      "                                            aten::alias         0.00%      46.801us         0.01%     229.934us      57.483us       0.000us         0.00%       0.000us       0.000us             4  \n",
      "                                         prims::squeeze         0.00%      44.957us         0.00%      51.023us      51.023us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                     aten::masked_fill_         0.00%      40.133us         0.00%      71.564us      17.891us       9.439us         0.02%       9.439us       2.360us             4  \n",
      "                                       aten::bitwise_or         0.00%      33.599us         0.00%      49.808us      12.452us       9.729us         0.02%       9.729us       2.432us             4  \n",
      "                                   aten::empty_permuted         0.00%      33.041us         0.00%      41.817us      41.817us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                              aten::any         0.00%      33.013us         0.00%      90.323us      18.065us       0.000us         0.00%      11.871us       2.374us             5  \n",
      "                                        aten::embedding         0.00%      32.644us         0.00%      94.576us      47.288us       0.000us         0.00%       7.936us       3.968us             2  \n",
      "                                           aten::arange         0.00%      30.730us         0.00%     114.320us      14.290us       8.704us         0.02%      17.408us       2.176us             8  \n",
      "                                     aten::index_select         0.00%      30.461us         0.00%      58.228us      29.114us       7.936us         0.01%       7.936us       3.968us             2  \n",
      "                              aten::_local_scalar_dense         0.00%      28.295us         0.00%     114.979us      19.163us      13.376us         0.02%      13.376us       2.229us             6  \n",
      "                                                detach_         0.00%      24.808us         0.00%      24.808us       0.468us       0.000us         0.00%       0.000us       0.000us            53  \n",
      "                                              aten::max         0.00%      21.988us         0.00%      40.802us      20.401us      10.017us         0.02%      10.017us       5.008us             2  \n",
      "                                               aten::ge         0.00%      21.861us         0.00%      32.674us      16.337us       4.512us         0.01%       4.512us       2.256us             2  \n",
      "                                           aten::argmax         0.00%      21.826us         0.00%      36.740us      18.370us      24.417us         0.04%      24.417us      12.208us             2  \n",
      "                                          aten::dropout         0.00%      21.357us         0.00%      21.357us       0.334us       0.000us         0.00%       0.000us       0.000us            64  \n",
      "                                               aten::gt         0.00%      21.223us         0.00%      37.277us      18.638us       5.728us         0.01%       5.728us       2.864us             2  \n",
      "                                      aten::bitwise_or_         0.00%      19.328us         0.00%      30.537us      15.268us       5.280us         0.01%       5.280us       2.640us             2  \n",
      "                                    cudaStreamWaitEvent         0.00%      17.347us         0.00%      17.347us       1.577us       0.000us         0.00%       0.000us       0.000us            11  \n",
      "                                               aten::lt         0.00%      16.494us         0.00%      27.216us      27.216us       2.272us         0.00%       2.272us       2.272us             1  \n",
      "                                             aten::mul_         0.00%      16.095us         0.00%      30.868us      15.434us       5.664us         0.01%       5.664us       2.832us             2  \n",
      "                                      aten::bitwise_not         0.00%      15.908us         0.00%      26.122us      13.061us       4.672us         0.01%       4.672us       2.336us             2  \n",
      "                                      aten::bitwise_and         0.00%      14.886us         0.00%      25.816us      12.908us       5.662us         0.01%       5.662us       2.831us             2  \n",
      "                                 cudaStreamBeginCapture         0.00%      12.850us         0.00%      12.850us       4.283us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                             aten::rsub         0.00%      11.944us         0.00%      37.540us      18.770us       0.000us         0.00%       4.832us       2.416us             2  \n",
      "                                         cuLaunchKernel         0.00%      11.775us         0.00%      11.775us       5.888us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                                               aten::le         0.00%      11.495us         0.00%      17.313us       8.657us       5.440us         0.01%       5.440us       2.720us             2  \n",
      "                                             aten::full         0.00%      11.259us         0.00%      71.189us      11.865us       0.000us         0.00%      13.023us       2.170us             6  \n",
      "                                      aten::masked_fill         0.00%       9.541us         0.00%      56.020us      28.010us       0.000us         0.00%       9.185us       4.592us             2  \n",
      "                                       aten::is_nonzero         0.00%       9.263us         0.00%     132.830us      22.138us       0.000us         0.00%      13.376us       2.229us             6  \n",
      "                                             aten::item         0.00%       8.588us         0.00%     123.567us      20.594us       0.000us         0.00%      13.376us       2.229us             6  \n",
      "                                         aten::new_ones         0.00%       8.299us         0.00%      31.305us      15.653us       0.000us         0.00%       5.151us       2.576us             2  \n",
      "                                       cudaGraphDestroy         0.00%       7.625us         0.00%       7.625us       2.542us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                   cudaStreamEndCapture         0.00%       7.304us         0.00%       7.304us       2.435us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                           aten::__or__         0.00%       5.989us         0.00%      55.797us      13.949us       0.000us         0.00%       9.729us       2.432us             4  \n",
      "                                      cudaGraphGetNodes         0.00%       5.755us         0.00%       5.755us       1.918us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                          aten::__and__         0.00%       5.052us         0.00%      30.868us      15.434us       0.000us         0.00%       5.662us       2.831us             2  \n",
      "                                             aten::ones         0.00%       4.493us         0.00%      21.156us      21.156us       0.000us         0.00%       2.272us       2.272us             1  \n",
      "                                          aten::view_as         0.00%       3.998us         0.00%       5.905us       1.181us       0.000us         0.00%       0.000us       0.000us             5  \n",
      "                               cudaStreamGetCaptureInfo         0.00%       3.598us         0.00%       3.598us       0.900us       0.000us         0.00%       0.000us       0.000us             4  \n",
      "                                        aten::ones_like         0.00%       2.326us         0.00%      13.273us      13.273us       0.000us         0.00%       2.048us       2.048us             1  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      46.592us         0.08%      46.592us       1.607us            29  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      14.912us         0.03%      14.912us       2.130us             7  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.272us         0.00%       2.272us       2.272us             1  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      10.910ms        19.43%      10.910ms       6.414us          1701  \n",
      "                         Memcpy DtoH (Device -> Pinned)         0.00%       0.000us         0.00%       0.000us       0.000us       1.216ms         2.17%       1.216ms       2.348us           518  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       6.784us         0.01%       6.784us       2.261us             3  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.436ms         4.34%       2.436ms       2.227us          1094  \n",
      "void at_cuda_detail::cub::DeviceScanInitKernel<at_cu...         0.00%       0.000us         0.00%       0.000us       0.000us       6.977us         0.01%       6.977us       2.326us             3  \n",
      "void at_cuda_detail::cub::DeviceScanKernel<at_cuda_d...         0.00%       0.000us         0.00%       0.000us       0.000us       8.640us         0.02%       8.640us       2.880us             3  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      16.865us         0.03%      16.865us       2.409us             7  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       9.280us         0.02%       9.280us       2.320us             4  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.735us         0.01%       4.735us       2.368us             2  \n",
      "void at::native::(anonymous namespace)::indexSelectS...         0.00%       0.000us         0.00%       0.000us       0.000us       7.936us         0.01%       7.936us       3.968us             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     350.274us         0.62%     350.274us       1.806us           194  \n",
      "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us       8.704us         0.02%       8.704us       2.176us             4  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.120us         0.01%       5.120us       2.560us             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      15.009us         0.03%      15.009us       2.501us             6  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       5.664us         0.01%       5.664us       2.832us             2  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       5.441us         0.01%       5.441us       2.720us             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.801us         0.01%       4.801us       2.401us             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.704us         0.01%       4.704us       2.352us             2  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     472.551us         0.84%     472.551us       3.580us           132  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     311.625us         0.55%     311.625us       2.397us           130  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     689.895us         1.23%     689.895us       5.307us           130  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     323.679us         0.58%     323.679us       2.490us           130  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     321.533us         0.57%     321.533us       2.473us           130  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     437.705us         0.78%     437.705us       3.367us           130  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     825.264us         1.47%     825.264us       3.199us           258  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     696.035us         1.24%     696.035us       2.698us           258  \n",
      "sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize32x32x...         0.00%       0.000us         0.00%       0.000us       0.000us       2.546ms         4.53%       2.546ms      19.889us           128  \n",
      "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us       1.067ms         1.90%       1.067ms       8.334us           128  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.786ms         3.18%       1.786ms       4.652us           384  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.502ms         2.67%       1.502ms       3.910us           384  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     457.483us         0.81%     457.483us       3.574us           128  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     561.482us         1.00%     561.482us       4.387us           128  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     646.152us         1.15%     646.152us       2.524us           256  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     432.707us         0.77%     432.707us       3.381us           128  \n",
      "void gemv2T_kernel_val<int, int, __half, __half, __h...         0.00%       0.000us         0.00%       0.000us       0.000us     207.843us         0.37%     207.843us       3.248us            64  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     153.260us         0.27%     153.260us       2.395us            64  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     200.678us         0.36%     200.678us       3.136us            64  \n",
      "void (anonymous namespace)::softmax_warp_forward<c10...         0.00%       0.000us         0.00%       0.000us       0.000us      80.227us         0.14%      80.227us       2.507us            32  \n",
      "void gemmk1_kernel<int, float, 256, 5, false, false,...         0.00%       0.000us         0.00%       0.000us       0.000us      93.955us         0.17%      93.955us       2.936us            32  \n",
      "void dot_kernel<float, 128, 0, cublasDotParams<cubla...         0.00%       0.000us         0.00%       0.000us       0.000us     189.856us         0.34%     189.856us       2.966us            64  \n",
      "void reduce_1Block_kernel<float, 128, 7, cublasGemvT...         0.00%       0.000us         0.00%       0.000us       0.000us     173.312us         0.31%     173.312us       2.708us            64  \n",
      "void (anonymous namespace)::softmax_warp_forward<c10...         0.00%       0.000us         0.00%       0.000us       0.000us     161.632us         0.29%     161.632us       2.525us            64  \n",
      "void at::native::sbtopk::gatherTopK<float, unsigned ...         0.00%       0.000us         0.00%       0.000us       0.000us     449.994us         0.80%     449.994us       7.031us            64  \n",
      "void at::native::bitonicSortKVInPlace<-2, -1, 16, 16...         0.00%       0.000us         0.00%       0.000us       0.000us     371.138us         0.66%     371.138us       5.799us            64  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     277.191us         0.49%     277.191us       4.331us            64  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     185.959us         0.33%     185.959us       2.906us            64  \n",
      "void at::native::_scatter_gather_elementwise_kernel<...         0.00%       0.000us         0.00%       0.000us       0.000us     188.967us         0.34%     188.967us       2.953us            64  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.526ms         2.72%       1.526ms       2.981us           512  \n",
      "void at_cuda_detail::cub::DeviceReduceSingleTileKern...         0.00%       0.000us         0.00%       0.000us       0.000us       1.376ms         2.45%       1.376ms       2.687us           512  \n",
      "void at_cuda_detail::cub::DeviceCompactInitKernel<at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.251ms         2.23%       1.251ms       2.443us           512  \n",
      "void at_cuda_detail::cub::DeviceSelectSweepKernel<at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.452ms         2.59%       1.452ms       2.837us           512  \n",
      "    compile_fx.<locals>.fw_compiler_base (dynamo_timed)         0.00%       0.000us         0.00%       0.000us       0.000us      51.930ms        92.48%      51.930ms      51.930ms             1  \n",
      "void at::native::indexFuncSmallIndex<c10::Half, long...         0.00%       0.000us         0.00%       0.000us       0.000us       1.316ms         2.34%       1.316ms       2.570us           512  \n",
      "void at::native::(anonymous namespace)::write_indice...         0.00%       0.000us         0.00%       0.000us       0.000us     535.439us         0.95%     535.439us       4.183us           128  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     204.525us         0.36%     204.525us       1.573us           130  \n",
      "sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize64x64x...         0.00%       0.000us         0.00%       0.000us       0.000us       6.753ms        12.03%       6.753ms      51.947us           130  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     422.659us         0.75%     422.659us       3.302us           128  \n",
      "          gemv_revsplitK_A16fWnO16f_int32packing_kernel         0.00%       0.000us         0.00%       0.000us       0.000us       2.859ms         5.09%       2.859ms      22.338us           128  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_s16816gemm_...         0.00%       0.000us         0.00%       0.000us       0.000us       6.578ms        11.72%       6.578ms      51.393us           128  \n",
      "void splitKreduce_kernel<32, 16, int, float, __half,...         0.00%       0.000us         0.00%       0.000us       0.000us     466.759us         0.83%     466.759us       3.647us           128  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      13.215us         0.02%      13.215us       3.304us             4  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      24.417us         0.04%      24.417us      12.208us             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      10.751us         0.02%      10.751us       2.688us             4  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.832us         0.01%       4.832us       2.416us             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.504us         0.01%       5.504us       2.752us             2  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       2.400us         0.00%       2.400us       2.400us             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.672us         0.01%       4.672us       2.336us             2  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       5.662us         0.01%       5.662us       2.831us             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      10.017us         0.02%      10.017us       5.008us             2  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.968us         0.01%       3.968us       3.968us             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       6.048us         0.01%       6.048us       3.024us             2  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     226.397us         0.40%     226.397us       3.537us            64  \n",
      "void (anonymous namespace)::softmax_warp_forward<c10...         0.00%       0.000us         0.00%       0.000us       0.000us      80.575us         0.14%      80.575us       2.518us            32  \n",
      "void gemv2N_kernel<int, int, __half, __half, __half,...         0.00%       0.000us         0.00%       0.000us       0.000us     111.394us         0.20%     111.394us       3.481us            32  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.464us         0.00%       2.464us       2.464us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.659s\n",
      "Self CUDA time total: 56.151ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "input_length = 1\n",
    "MAX_LENGTH = input_length\n",
    "output_length = 2\n",
    "test_samples = 4\n",
    "\n",
    "with open(\"../path.json\", \"r\") as f:\n",
    "    paths = json.load(f)\n",
    "    fineweb_path = paths[\"fineweb\"]\n",
    "\n",
    "def preprocess_data(data, tokenizer):\n",
    "\t# 使用 tokenizer 将文本数据转换为模型输入\n",
    "\tinputs = tokenizer(data, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
    "\tinputs[\"labels\"] = inputs.input_ids.clone()\n",
    "\treturn inputs\n",
    "\n",
    "fineweb = load_dataset(\"parquet\",data_files=fineweb_path) #726000\n",
    "fineweb_text = fineweb['train']['text'][:test_samples] \n",
    "\n",
    "print(\"output length is {}\".format(output_length))\n",
    "text = fineweb_text[0]\n",
    "inputs = preprocess_data(text, tokenizer)\n",
    "\n",
    "# cached_mlp.clear_load_from_cpu_stats()\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA,\n",
    "    ]\n",
    ") as p:\n",
    "    # 前向传播\n",
    "    with torch.no_grad():\n",
    "        output = llm.generate(\n",
    "            input_ids=inputs[\"input_ids\"].cuda(),\n",
    "            attention_mask=inputs[\"attention_mask\"].cuda(),\n",
    "            max_length=input_length + output_length,  # 总长度为输入长度 + 输出长度\n",
    "            generation_config=GenerationConfig(do_sample=False),\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "print(p.key_averages().table(\n",
    "    sort_by=\"self_cpu_time_total\", row_limit=-1))\n",
    "p.export_chrome_trace(\"./compile.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
