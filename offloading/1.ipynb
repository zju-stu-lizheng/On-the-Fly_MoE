{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先都加载到cpu上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 19/19 [00:07<00:00,  2.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "# from modeling_mixtral import MixtralForCausalLM\n",
    "from transformers import AutoTokenizer, MixtralForCausalLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "with open('../path.json', 'r') as f:\n",
    "    path = json.load(f)\n",
    "    model_name = path['mixtral']\n",
    "    # threshold_path = path[threshold_path_name]\n",
    "\n",
    "with open(\"../quantize/device_map.json\", \"r\") as f:\n",
    "    device_map = json.load(f)\n",
    "\n",
    "def get_model(model_name, device_map, dtype=torch.bfloat16, use_cache=True):\n",
    "    llm = MixtralForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=device_map,\n",
    "        use_cache=use_cache,\n",
    "        torch_dtype=dtype,\n",
    "    ) \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    return llm, tokenizer\n",
    "\n",
    "dtype = torch.float16\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "llm, tokenizer = get_model(model_name, 'cpu', dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcds/venv/dilab/floe/hqq/hqq/models/base.py:251: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(cls.get_weight_file(save_dir), map_location=map_location)\n",
      "100%|██████████| 32/32 [00:00<00:00, 270.19it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 1171.06it/s]\n"
     ]
    }
   ],
   "source": [
    "### HQQ量化\n",
    "from hqq.core.quantize import *\n",
    "from hqq.models.hf.mixtral import MixtralHQQ\n",
    "\n",
    "# save_dir = './hqqsaved'\n",
    "### 第一次加载\n",
    "# q3_config    = BaseQuantizeConfig(nbits=2, group_size=64)\n",
    "# quant_config      = {'block_sparse_moe.experts.w3'   : q3_config}\n",
    "# llm = MixtralForCausalLM.from_pretrained(\n",
    "#         model_name,\n",
    "#         device_map='cpu',\n",
    "#         use_cache=True,\n",
    "#         torch_dtype=dtype,\n",
    "#     ) \n",
    "# MixtralHQQ.quantize_model(llm, quant_config=quant_config, compute_dtype=dtype, device='cuda:0')\n",
    "#### 先放CUDA量化，然后再传回CPU\n",
    "# MixtralHQQ.save_quantized(llm, save_dir)\n",
    "\n",
    "### 从保存的权重中加载\n",
    "# llm = MixtralHQQ.from_quantized(save_dir, compute_dtype=dtype, device='cpu')\n",
    "# HQQLinear.set_backend(HQQBackend.PYTORCH)\n",
    "\n",
    "# backend       = \"gemlite\" #'torchao_int4' #\"torchao_int4\" (4-bit only) or \"gemlite\" (4-bit + 2-bit)\n",
    "# #Optimize\n",
    "# from hqq.utils.patching import prepare_for_inference\n",
    "# prepare_for_inference(llm, backend=backend, verbose=True)\n",
    "# #Load GemLite cache\n",
    "# if(backend == 'gemlite'):\n",
    "# \timport gemlite\n",
    "# \tgemlite.core.GEMLITE_TRITON_RESTRICT_M = True\n",
    "# \tgemlite.core.GemLiteLinear.load_config('/tmp/gemlite_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import threading\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#### 增加专家preload失败后的重新加载\n",
    "class CachedMLP(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, dtype, sparsity: float = 0.2):\n",
    "        super(CachedMLP, self).__init__()\n",
    "        self.sparsity = sparsity\n",
    "        self.activenum = int((1 - sparsity) * hidden_dim)\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dtype = dtype\n",
    "        print(\"active neural num \",self.activenum)\n",
    "\n",
    "        self.activation = nn.SiLU()\n",
    "\n",
    "        #### 中间变量\n",
    "        self.w3_result1 = None\n",
    "        self.w3_result2 = None\n",
    "\n",
    "        # 将GPU缓存张量改为列表存储\n",
    "        self.w_gpu = [\n",
    "            torch.empty((self.activenum, self.input_dim), dtype=self.dtype, device='cuda:0') for _ in range(4)\n",
    "        ]  # [w1_gpu, w2_gpu, w1_gpu_expert1, w2_gpu_expert1]\n",
    "\n",
    "        # 将Pinned Memory缓冲区改为列表存储\n",
    "        self.sparse_w_cpu = [\n",
    "            torch.empty((self.activenum, self.input_dim), dtype=self.dtype, device='cpu').pin_memory() for _ in range(4)\n",
    "        ]  # [sparse_w1_cpu, sparse_w2_cpu, sparse_w1_cpu_expert1, sparse_w2_cpu_expert1]\n",
    "\n",
    "        ### 增加两个专家序号\n",
    "        self.expert_ids = torch.tensor([0,1])\n",
    "\n",
    "    def get_predict_experts(self):\n",
    "        return self.expert_ids\n",
    "    \n",
    "    def load_conflict_cpu(self, cpu_mlp_new, stream: torch.cuda.Stream, hidden_states, reuse_idx):\n",
    "        # 只更新需要加载的专家权重\n",
    "        _, indices = torch.topk(cpu_mlp_new['w3'](hidden_states), self.activenum, dim=1)\n",
    "        indices = indices[0].cpu()\n",
    "        if reuse_idx == 0:\n",
    "            # 更新CPU数据\n",
    "            self.sparse_w_cpu[2].copy_(cpu_mlp_new['w1'].data[indices, :])\n",
    "            self.sparse_w_cpu[3].copy_(cpu_mlp_new['w2'].data[indices, :])\n",
    "            \n",
    "            # 异步复制到GPU\n",
    "            with torch.cuda.stream(stream):\n",
    "                self.w_gpu[2].copy_(self.sparse_w_cpu[2], non_blocking=True)\n",
    "                self.w_gpu[3].copy_(self.sparse_w_cpu[3], non_blocking=True)\n",
    "        else:\n",
    "            # 更新CPU数据\n",
    "            self.sparse_w_cpu[0].copy_(cpu_mlp_new['w1'].data[indices, :])\n",
    "            self.sparse_w_cpu[1].copy_(cpu_mlp_new['w2'].data[indices, :])\n",
    "            \n",
    "            # 异步复制到GPU\n",
    "            with torch.cuda.stream(stream):\n",
    "                self.w_gpu[0].copy_(self.sparse_w_cpu[0], non_blocking=True)\n",
    "                self.w_gpu[1].copy_(self.sparse_w_cpu[1], non_blocking=True)\n",
    "\n",
    "    def load_from_cpu(self, cpu_mlp, cpu_mlp_expert1, stream: torch.cuda.Stream, hidden_states):\n",
    "        \"\"\"\n",
    "        从CPU加载参数，并使用指定的CUDA流进行异步复制到GPU。\n",
    "        \n",
    "        参数:\n",
    "            cpu_mlp: 包含CPU上参数的字典（第一个专家）\n",
    "            cpu_mlp_expert1: 包含CPU上参数的字典（第二个专家）。\n",
    "            stream: 用于数据传输的CUDA流。\n",
    "        \"\"\"\n",
    "        ### 根据up计算的结果进行稀疏化\n",
    "        up_result1 = cpu_mlp['w3'](hidden_states)\n",
    "        up_result2 = cpu_mlp_expert1['w3'](hidden_states)\n",
    "        # 提取 up_result1 的值并计算 top-k 索引\n",
    "        _, indices1 = torch.topk(up_result1, self.activenum, dim=1)  # 在第二个维度上取 top-k\n",
    "        self.w3_result1 = up_result1[: , indices1[0]]\n",
    "        indices1 = indices1[0].cpu()\n",
    "\n",
    "        _, indices2 = torch.topk(up_result2, self.activenum, dim=1)  # 在第二个维度上取 top-k\n",
    "        self.w3_result2 = up_result2[: , indices2[0]]\n",
    "        indices2 = indices2[0].cpu() \n",
    "\n",
    "        # 使用列表索引更新CPU数据\n",
    "        self.sparse_w_cpu[0].copy_(cpu_mlp['w1'].data[indices1, :])\n",
    "        self.sparse_w_cpu[1].copy_(cpu_mlp['w2'].data[indices1, :])\n",
    "        self.sparse_w_cpu[2].copy_(cpu_mlp_expert1['w1'].data[indices2, :])\n",
    "        self.sparse_w_cpu[3].copy_(cpu_mlp_expert1['w2'].data[indices2, :])\n",
    "        \n",
    "        # 异步复制到GPU\n",
    "        with torch.cuda.stream(stream):\n",
    "            self.w_gpu[0].copy_(self.sparse_w_cpu[0], non_blocking=True)\n",
    "            self.w_gpu[1].copy_(self.sparse_w_cpu[1], non_blocking=True)\n",
    "            self.w_gpu[2].copy_(self.sparse_w_cpu[2], non_blocking=True)\n",
    "            self.w_gpu[3].copy_(self.sparse_w_cpu[3], non_blocking=True)\n",
    "\n",
    "    def load_expert_weights(self, expert_ids):\n",
    "        # print('loading next expert: ', expert_ids)   ## tensor([7, 6], device='cuda:0')\n",
    "        self.expert_ids = expert_ids\n",
    "\n",
    "    def forward(self, hidden_states, expert_weights, expert_ids):\n",
    "        \"\"\"\n",
    "        根据hidden_states， 分别计算两个专家的输出\n",
    "        \"\"\"\n",
    "        ### 如果取出来的专家 第一个对不上，可能是预测的 1，2号专家顺序颠倒了，替换\n",
    "        if self.expert_ids[0] != expert_ids[0]:\n",
    "            expert_weights[0], expert_weights[1] = expert_weights[1], expert_weights[0]\n",
    "\n",
    "        w3_output = self.w3_result1\n",
    "        w1_output = self.activation(torch.matmul(hidden_states, self.w_gpu[0].T))\n",
    "        hidden_states_expert0 = torch.matmul(w1_output * w3_output, self.w_gpu[1])\n",
    "\n",
    "        # 第二个专家的计算\n",
    "        w3_output_expert1 = self.w3_result2\n",
    "        w1_output_expert1 = self.activation(torch.matmul(hidden_states, self.w_gpu[2].T))\n",
    "        hidden_states_expert1 = torch.matmul(w1_output_expert1 * w3_output_expert1, self.w_gpu[3])\n",
    "\n",
    "        final_hidden_states = hidden_states_expert0 * expert_weights[0] + hidden_states_expert1 * expert_weights[1]\n",
    "        return final_hidden_states\n",
    "                    \n",
    "\n",
    "class PipelineLLM:\n",
    "    def __init__(self, llm, cached_mlps):\n",
    "        \"\"\"\n",
    "        初始化 PipelineLLM，替换模型每一层的 forward 方法。\n",
    "        \n",
    "        参数:\n",
    "            llm: 原始的大模型\n",
    "            cached_mlps: 两个 CachedMLP 实例列表\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.cached_mlps = cached_mlps  # [buffer0, buffer1]\n",
    "        self.num_layers = len(llm.model.layers)\n",
    "        self.lock = threading.Lock()\n",
    "        self.use_buffer0 = True  # 标记当前使用哪个缓冲区\n",
    "\n",
    "        self.stream0 = torch.cuda.Stream()\n",
    "\n",
    "        self.top_k = 2\n",
    "        self.activation = nn.SiLU()\n",
    "\n",
    "        self._replace_forward_methods()\n",
    "\n",
    "        # 用于统计时间的变量\n",
    "        self.total_reload_experts = 0\n",
    "    \n",
    "    def get_reload_experts(self):\n",
    "        return self.total_reload_experts\n",
    "\n",
    "    def print_reload_experts(self):\n",
    "        print(\"all reload experts are:\", self.total_reload_experts)\n",
    "        self.total_reload_experts = 0\n",
    "\n",
    "    def _load_layer(self, layer_idx, buffer, expert_ids,\n",
    "                    hidden_states):\n",
    "        \"\"\"\n",
    "        加载指定层的参数到指定的缓冲区。\n",
    "        \n",
    "        参数:\n",
    "            layer_idx: 层的索引\n",
    "            buffer_index: 缓冲区的索引（0 或 1）\n",
    "        \"\"\"\n",
    "        layer = self.llm.model.layers[layer_idx]\n",
    "        expert0 = layer.block_sparse_moe.experts[expert_ids[0]]\n",
    "        expert1 = layer.block_sparse_moe.experts[expert_ids[1]]\n",
    "\n",
    "        cpu_mlp = expert0.cpu_mlp\n",
    "        cpu_mlp_expert1 = expert1.cpu_mlp\n",
    "\n",
    "        ### weights应该用正确的来算\n",
    "        buffer.load_expert_weights(expert_ids)\n",
    "        # 异步加载参数\n",
    "        buffer.load_from_cpu(cpu_mlp, cpu_mlp_expert1, self.stream0, hidden_states)\n",
    "\n",
    "    def _load_conflict_layer(self, layer_idx, buffer, expert_ids, hidden_states):\n",
    "        \"\"\"\n",
    "        处理专家预测冲突的情况，尽可能复用已加载的专家权重\n",
    "        \n",
    "        参数:\n",
    "            layer_idx: 层索引\n",
    "            buffer_index: 缓冲区索引\n",
    "            expert_ids: 实际需要的专家ID\n",
    "            predict_experts: 预测的专家ID\n",
    "            hidden_states: 输入hidden_states\n",
    "        \"\"\"\n",
    "        predict_experts = buffer.get_predict_experts()\n",
    "        print(f\"predict_experts in layer {layer_idx}: {predict_experts}\")\n",
    "        # 找出需要加载的新专家\n",
    "        required_experts = set(expert_ids.tolist()) - set(predict_experts.tolist())\n",
    "        \n",
    "        # 如果只需要加载一个专家\n",
    "        if len(required_experts) == 1:\n",
    "            new_expert_id = list(required_experts)[0]\n",
    "            # 找出可以复用的专家位置\n",
    "            reuse_idx = 0 if expert_ids[0] in predict_experts else 1\n",
    "\n",
    "            print(f\"reloading 1 experts, {expert_ids[1-reuse_idx]}\")\n",
    "            self.total_reload_experts += 1\n",
    "            \n",
    "            # 获取需要加载的专家\n",
    "            layer = self.llm.model.layers[layer_idx]\n",
    "            new_expert = layer.block_sparse_moe.experts[new_expert_id]\n",
    "            cpu_mlp_new = new_expert.cpu_mlp\n",
    "            \n",
    "            # 只更新需要加载的专家权重\n",
    "            buffer.load_conflict_cpu(cpu_mlp_new, self.stream0, hidden_states, reuse_idx)\n",
    "            \n",
    "            # 更新专家ID\n",
    "            buffer.load_expert_weights(expert_ids)\n",
    "        else:\n",
    "            print(f\"reloading 2 experts, {expert_ids[:]}\")\n",
    "            self.total_reload_experts += 2\n",
    "            # 需要加载两个专家，直接调用原始方法\n",
    "            self._load_layer(layer_idx, buffer, expert_ids, hidden_states)\n",
    "\n",
    "    def _replace_forward_methods(self):\n",
    "        \"\"\"\n",
    "        替换模型每一层的 forward 方法，添加参数预加载逻辑和注意力计算。\n",
    "        \"\"\"\n",
    "        for i, layer in enumerate(self.llm.model.layers):\n",
    "            def new_forward(hidden_states: torch.Tensor,\n",
    "                        attention_mask: Optional[torch.Tensor] = None,\n",
    "                        position_ids: Optional[torch.LongTensor] = None,\n",
    "                        past_key_value: Optional[Tuple[torch.Tensor]] = None,\n",
    "                        output_attentions: Optional[bool] = False,\n",
    "                        output_router_logits: Optional[bool] = False,\n",
    "                        use_cache: Optional[bool] = False,\n",
    "                        cache_position: Optional[torch.LongTensor] = None,\n",
    "                        layer=layer,\n",
    "                        layer_idx=i):\n",
    "                with self.lock:\n",
    "                    batch_size, sequence_length, hidden_dim = hidden_states.shape\n",
    "                    \n",
    "                    if sequence_length == 1:\n",
    "                        #### decode phase ####\n",
    "                        # 选择当前使用的缓冲区\n",
    "                        current_buffer = self.cached_mlps[0] if self.use_buffer0 else self.cached_mlps[1]\n",
    "                        \n",
    "                        next_buffer_index = 1 if self.use_buffer0 else 0\n",
    "                        next_layer_idx = layer_idx + 1\n",
    "                        if next_layer_idx < self.num_layers:\n",
    "                            ### 使用下一个缓冲区进行加载\n",
    "                            next_buffer = self.cached_mlps[next_buffer_index]\n",
    "\n",
    "                            # 预加载下一层的参数\n",
    "                            next_layer = self.llm.model.layers[next_layer_idx]\n",
    "                            router = next_layer.block_sparse_moe.gate\n",
    "\n",
    "                            # batch_size, sequence_length, hidden_dim = hidden_states.shape\n",
    "                            hidden_states_flat = hidden_states.view(-1, hidden_dim)\n",
    "                            # router_logits: (batch * sequence_length, n_experts)\n",
    "                            router_logits = router(hidden_states_flat)\n",
    "\n",
    "                            routing_weights = F.softmax(router_logits, dim=1, dtype=torch.float)\n",
    "                            routing_weights, selected_experts = torch.topk(routing_weights, self.top_k, dim=-1)\n",
    "                            routing_weights /= routing_weights.sum(dim=-1, keepdim=True)\n",
    "\n",
    "                            self._load_layer(\n",
    "                                next_layer_idx,\n",
    "                                buffer=next_buffer,\n",
    "                                expert_ids=selected_experts[0],\n",
    "                                hidden_states=hidden_states_flat,\n",
    "                            )\n",
    "                            hidden_states = hidden_states_flat.reshape(batch_size, sequence_length, hidden_dim)\n",
    "\n",
    "                            # 切换缓冲区\n",
    "                            self.use_buffer0 = not self.use_buffer0\n",
    "\n",
    "                    # 处理当前层\n",
    "                    residual = hidden_states\n",
    "                    hidden_states = layer.input_layernorm(hidden_states)\n",
    "\n",
    "                    # Self Attention\n",
    "                    hidden_states, self_attn_weights, present_key_value = layer.self_attn(\n",
    "                        hidden_states=hidden_states,\n",
    "                        attention_mask=attention_mask,\n",
    "                        position_ids=position_ids,\n",
    "                        past_key_value=past_key_value,\n",
    "                        output_attentions=output_attentions,\n",
    "                        use_cache=use_cache,\n",
    "                        cache_position=cache_position,\n",
    "                    )\n",
    "                    hidden_states = residual + hidden_states\n",
    "\n",
    "                    # Fully Connected\n",
    "                    residual = hidden_states\n",
    "                    hidden_states = layer.post_attention_layernorm(hidden_states)\n",
    "                    \n",
    "                    if sequence_length > 1:\n",
    "                        # print(\"in prefill layer \", layer_idx)\n",
    "                        # 对于prefill阶段，仅将experts加载到GPU计算\n",
    "                        experts = layer.block_sparse_moe.experts\n",
    "\n",
    "                        # 将experts移动到GPU\n",
    "                        if layer_idx != 0:\n",
    "                            for expert in experts:\n",
    "                                expert.cuda(0)\n",
    "\n",
    "                        # 在GPU上进行MoE计算（gate保持在CPU）\n",
    "                        final_hidden_states, router_logits = layer.block_sparse_moe(hidden_states)\n",
    "\n",
    "                        # 计算完成后将experts移回CPU\n",
    "                        if layer_idx != 0:\n",
    "                            for expert in experts:\n",
    "                                expert.w1.to('cpu')\n",
    "                                expert.w2.to('cpu')\n",
    "                    else:\n",
    "                        # print(\"in decode layer\", layer_idx)\n",
    "                        hidden_states_flat = hidden_states.view(-1, hidden_dim)\n",
    "                        ### 根据router计算需要使用的专家 ###\n",
    "                        router = layer.block_sparse_moe.gate\n",
    "                        # router_logits: (batch * sequence_length, n_experts)\n",
    "                        router_logits = router(hidden_states_flat)\n",
    "\n",
    "                        routing_weights = F.softmax(router_logits, dim=1, dtype=torch.float)\n",
    "                        routing_weights, selected_experts = torch.topk(routing_weights, self.top_k, dim=-1)\n",
    "                        routing_weights /= routing_weights.sum(dim=-1, keepdim=True)\n",
    "                        # we cast back to the input dtype\n",
    "                        routing_weights = routing_weights.to(hidden_states_flat.dtype)\n",
    "                        expert_ids = selected_experts[0]\n",
    "                        expert_weights = routing_weights[0]\n",
    "                        # print('the right experts is', expert_ids)\n",
    "                        ## tensor([6, 7], device='cuda:0')\n",
    "                        if layer_idx > 0:\n",
    "                            ### 判断加载是否正确\n",
    "                            predict_experts = current_buffer.get_predict_experts()\n",
    "                            \n",
    "                            # 判断expert_ids和predict_experts是否包含相同数据（忽略顺序）\n",
    "                            if not torch.equal(torch.sort(expert_ids)[0], torch.sort(predict_experts)[0]):\n",
    "                                ### 不吻合，重新加载\n",
    "                                self._load_conflict_layer(\n",
    "                                    layer_idx,\n",
    "                                    buffer=current_buffer,## 用cur_buffer_index\n",
    "                                    expert_ids=expert_ids,\n",
    "                                    hidden_states=hidden_states_flat,\n",
    "                                )\n",
    "                                torch.cuda.synchronize()  # 等待所有CUDA操作完成                                \n",
    "                            \n",
    "                            ### 使用当前缓冲区进行 MLP 计算 ###\n",
    "                            final_hidden_states = current_buffer(hidden_states_flat, expert_weights, expert_ids)\n",
    "                        else:\n",
    "                            final_hidden_states_expert0 = layer.block_sparse_moe.experts[expert_ids[0]](\n",
    "                                hidden_states_flat) * expert_weights[0]\n",
    "\n",
    "                            final_hidden_states_expert1 = layer.block_sparse_moe.experts[expert_ids[1]](\n",
    "                                hidden_states_flat) * expert_weights[1]\n",
    "\n",
    "                            # 将两个专家的结果相加\n",
    "                            final_hidden_states = final_hidden_states_expert0 + final_hidden_states_expert1\n",
    "\n",
    "                        final_hidden_states = final_hidden_states.reshape(batch_size, sequence_length, hidden_dim)\n",
    "\n",
    "                    hidden_states = residual + final_hidden_states\n",
    "\n",
    "                    outputs = (hidden_states,)\n",
    "\n",
    "                    if output_attentions:\n",
    "                        outputs += (self_attn_weights,)\n",
    "\n",
    "                    if use_cache:\n",
    "                        outputs += (present_key_value,)\n",
    "\n",
    "                    return outputs\n",
    "\n",
    "            # 替换forward方法\n",
    "            layer.forward = new_forward\n",
    "\n",
    "def convert_mixtral_to_cached_mlp(llm, dtype, sparsity=0.9):\n",
    "    ### 其他部分存放在GPU上\n",
    "    llm.model.embed_tokens.cuda(0)\n",
    "    for i in range(len(llm.model.layers)):\n",
    "        llm.model.layers[i].self_attn.cuda(0)\n",
    "        llm.model.layers[i].input_layernorm.cuda(0)\n",
    "        llm.model.layers[i].post_attention_layernorm.cuda(0)\n",
    "        llm.model.layers[i].block_sparse_moe.gate.cuda(0)\n",
    "        for j in range(len(llm.model.layers[0].block_sparse_moe.experts)):\n",
    "            llm.model.layers[i].block_sparse_moe.experts[j].w3.cuda(0)\n",
    "    ### 第0层的专家存放在GPU上\n",
    "    for j in range(len(llm.model.layers[0].block_sparse_moe.experts)):\n",
    "        llm.model.layers[0].block_sparse_moe.experts[j].cuda(0)\n",
    "\n",
    "    llm.model.norm.cuda(0)\n",
    "    llm.lm_head.cuda(0)\n",
    "    \n",
    "    # 创建两个共享的CachedMLP实例\n",
    "    buffer0 = CachedMLP(\n",
    "        input_dim=llm.config.hidden_size,\n",
    "        hidden_dim=llm.config.intermediate_size,\n",
    "        dtype=dtype,\n",
    "        sparsity=sparsity\n",
    "    )\n",
    "    buffer1 = CachedMLP(\n",
    "        input_dim=llm.config.hidden_size,\n",
    "        hidden_dim=llm.config.intermediate_size,\n",
    "        dtype=dtype,\n",
    "        sparsity=sparsity\n",
    "    )\n",
    "    cached_mlps = [buffer0, buffer1]\n",
    "    \n",
    "    for i, layer in enumerate(llm.model.layers):\n",
    "        if i==0:\n",
    "            continue\n",
    "        # 将专家的forward方法替换为PipelineLLM管理的方式\n",
    "        for j, expert in enumerate(layer.block_sparse_moe.experts):\n",
    "            expert.cpu_mlp = {\n",
    "                \"w1\": expert.w1.cpu().weight,\n",
    "                \"w2\": expert.w2.cpu().weight.T.contiguous(),\n",
    "                \"w3\": expert.w3,\n",
    "            }\n",
    "    return llm, cached_mlps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active neural num  12902\n",
      "active neural num  12902\n"
     ]
    }
   ],
   "source": [
    "llm, cached_mlps = convert_mixtral_to_cached_mlp(llm, dtype, sparsity=0.1)\n",
    "\n",
    "# 创建流水线模型\n",
    "PLLM = PipelineLLM(llm, cached_mlps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试时间开销"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output length is 32\n",
      "predict_experts in layer 1: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 5: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 6: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 8: ftensor([4, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 6], device='cuda:0')\n",
      "predict_experts in layer 9: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 12: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 15: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 17: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([2, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 4], device='cuda:0')\n",
      "predict_experts in layer 19: ftensor([6, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 20: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 22: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 23: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 24: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 25: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 26: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 27: ftensor([1, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 3], device='cuda:0')\n",
      "predict_experts in layer 28: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 29: ftensor([5, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 30: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 1: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 5: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 6: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 8: ftensor([4, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 6], device='cuda:0')\n",
      "predict_experts in layer 9: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 12: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 15: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 17: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([2, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 4], device='cuda:0')\n",
      "predict_experts in layer 19: ftensor([6, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 20: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 22: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 23: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 24: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 25: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 26: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 27: ftensor([1, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 3], device='cuda:0')\n",
      "predict_experts in layer 28: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 29: ftensor([5, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 30: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 1: ftensor([0, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 2], device='cuda:0')\n",
      "predict_experts in layer 3: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([5, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([4, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 8: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 5], device='cuda:0')\n",
      "predict_experts in layer 11: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 6], device='cuda:0')\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 13: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 15: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 17: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 20: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 23: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 24: ftensor([1, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 29: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 30: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 31: ftensor([1, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 1: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 2: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 4: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 7: ftensor([4, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 0], device='cuda:0')\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 6], device='cuda:0')\n",
      "predict_experts in layer 15: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 20: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 22: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 26: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 27: ftensor([3, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 28: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 29: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 30: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 31: ftensor([5, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 6], device='cuda:0')\n",
      "predict_experts in layer 1: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 2], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 4: ftensor([3, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 0], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 6: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 15: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 18: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 26: ftensor([4, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 29: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 30: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 1: ftensor([6, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 4], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([1, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 4: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 7], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 6: ftensor([1, 3], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 11: ftensor([2, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 0], device='cuda:0')\n",
      "predict_experts in layer 12: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 14: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 15: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 17: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([5, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 0], device='cuda:0')\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 27: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 29: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 30: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 1: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 2: ftensor([7, 5], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 3: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([3, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 0], device='cuda:0')\n",
      "predict_experts in layer 12: ftensor([7, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 6], device='cuda:0')\n",
      "predict_experts in layer 14: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 15: ftensor([4, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 18: ftensor([7, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([0, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 21: ftensor([6, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 22: ftensor([0, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 5], device='cuda:0')\n",
      "predict_experts in layer 23: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 27: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 28: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 29: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 4], device='cuda:0')\n",
      "predict_experts in layer 30: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 1: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 2: ftensor([6, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 3: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([6, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 8: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 12: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 13: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 15: ftensor([7, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 1], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([2, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([7, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 6], device='cuda:0')\n",
      "predict_experts in layer 23: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 26: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 29: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 30: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 31: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 1: ftensor([5, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 2: ftensor([3, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 7], device='cuda:0')\n",
      "predict_experts in layer 3: ftensor([3, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 4: ftensor([5, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 1], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 7: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 8: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 11: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 13: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 14: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 15: ftensor([1, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 17: ftensor([7, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 3], device='cuda:0')\n",
      "predict_experts in layer 18: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([2, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 4], device='cuda:0')\n",
      "predict_experts in layer 21: ftensor([0, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 23: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 24: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 26: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 27: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 28: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 29: ftensor([5, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 6], device='cuda:0')\n",
      "predict_experts in layer 30: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 3: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 8: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 15: ftensor([7, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 1], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 17: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 24: ftensor([1, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 26: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 27: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 1: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 2: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 3: ftensor([6, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 8: ftensor([7, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 6], device='cuda:0')\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 13: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([6, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 15: ftensor([1, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 5], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 23: ftensor([3, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 24: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 28: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 31: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 1: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 2: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 4: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 6: ftensor([4, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 14: ftensor([1, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 3], device='cuda:0')\n",
      "predict_experts in layer 15: ftensor([7, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 4], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 22: ftensor([1, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 5], device='cuda:0')\n",
      "predict_experts in layer 23: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 24: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 26: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 28: ftensor([3, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 30: ftensor([6, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 7], device='cuda:0')\n",
      "predict_experts in layer 1: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 2: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 3: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 4: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 6: ftensor([6, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 1], device='cuda:0')\n",
      "predict_experts in layer 7: ftensor([0, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 5], device='cuda:0')\n",
      "predict_experts in layer 8: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 14: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 15: ftensor([2, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 17: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([6, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 22: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 23: ftensor([0, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 26: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 28: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 29: ftensor([7, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 31: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 1: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 2: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 3: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 4: ftensor([2, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([0, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 7], device='cuda:0')\n",
      "predict_experts in layer 7: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 8: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 12: ftensor([7, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 13: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 14: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 15: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 22: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 23: ftensor([0, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 5], device='cuda:0')\n",
      "predict_experts in layer 26: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 27: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 29: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 31: ftensor([3, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 7], device='cuda:0')\n",
      "predict_experts in layer 1: ftensor([2, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 7], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 3: ftensor([4, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 7], device='cuda:0')\n",
      "predict_experts in layer 4: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 5: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 8: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 15: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([1, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 7], device='cuda:0')\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 20: ftensor([2, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 22: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 23: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 24: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 27: ftensor([7, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 2], device='cuda:0')\n",
      "predict_experts in layer 28: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 29: ftensor([3, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 1], device='cuda:0')\n",
      "predict_experts in layer 30: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 3: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 4: ftensor([2, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 1], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([0, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 7], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 0], device='cuda:0')\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 13: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 0], device='cuda:0')\n",
      "predict_experts in layer 14: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 15: ftensor([7, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 3], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 20: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 21: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 24: ftensor([4, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 26: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 29: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 1: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 4: ftensor([2, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 5], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([2, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 5], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 7: ftensor([6, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 8: ftensor([1, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 9: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 13: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 15: ftensor([7, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 2], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([1, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 6], device='cuda:0')\n",
      "predict_experts in layer 17: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([2, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 7], device='cuda:0')\n",
      "predict_experts in layer 21: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 23: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 26: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 29: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 30: ftensor([7, 5], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 31: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 1: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 2: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 3: ftensor([6, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 4: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([6, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 7: ftensor([4, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 8: ftensor([7, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 2], device='cuda:0')\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 11: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 15: ftensor([2, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 22: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 25: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 28: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 30: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 1: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 2], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 3: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 4: ftensor([3, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 0], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([0, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 5], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([2, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 1], device='cuda:0')\n",
      "predict_experts in layer 7: ftensor([5, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 2], device='cuda:0')\n",
      "predict_experts in layer 13: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 15: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 20: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([7, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 22: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 27: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 28: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 30: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 1: ftensor([2, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 2: ftensor([7, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 3: ftensor([4, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 7], device='cuda:0')\n",
      "predict_experts in layer 4: ftensor([2, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 0], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([0, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 7], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 7], device='cuda:0')\n",
      "predict_experts in layer 7: ftensor([2, 3], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 12: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 14: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 15: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 22: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 23: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 24: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 25: ftensor([1, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 0], device='cuda:0')\n",
      "predict_experts in layer 27: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 28: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 29: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 31: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 1: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 3: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 4: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 7: ftensor([3, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 15: ftensor([6, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 1], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 18: ftensor([1, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 0], device='cuda:0')\n",
      "predict_experts in layer 19: ftensor([1, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 21: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 22: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 24: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 26: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 27: ftensor([1, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 6], device='cuda:0')\n",
      "predict_experts in layer 29: ftensor([2, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 31: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 1: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 4], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 3: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 4: ftensor([3, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 0], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([0, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 7], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 8: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 10: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 12: ftensor([4, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 2], device='cuda:0')\n",
      "predict_experts in layer 13: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 15: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 20: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([0, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 22: ftensor([7, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 2], device='cuda:0')\n",
      "predict_experts in layer 23: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 24: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 26: ftensor([3, 4], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 28: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 31: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 1: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 3: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 4: ftensor([2, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 0], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 8: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 14: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 15: ftensor([7, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 1], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 18: ftensor([1, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 7], device='cuda:0')\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([6, 4], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 22: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 23: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 26: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 28: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 29: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 30: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 7], device='cuda:0')\n",
      "predict_experts in layer 1: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 3: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 4: ftensor([3, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 5], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([1, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 7], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([2, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 0], device='cuda:0')\n",
      "predict_experts in layer 8: ftensor([4, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 10: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([7, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 2], device='cuda:0')\n",
      "predict_experts in layer 13: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 15: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 17: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 22: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 24: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([2, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 28: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 29: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 2: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 3: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 4: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 5: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 7: ftensor([0, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 8: ftensor([7, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 2], device='cuda:0')\n",
      "predict_experts in layer 9: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 12: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 15: ftensor([6, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 2], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 17: ftensor([7, 5], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 19: ftensor([1, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 20: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 23: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 24: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 26: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 27: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 29: ftensor([1, 3], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 4: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 5: ftensor([2, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 4], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 8: ftensor([3, 4], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 9: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 13: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 14: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 15: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 26: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 27: ftensor([6, 7], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 28: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 29: ftensor([2, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 30: ftensor([6, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 4], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 3: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 4: ftensor([3, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 5], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 8: ftensor([3, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 1], device='cuda:0')\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 14: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 20: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 23: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 24: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 26: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 28: ftensor([6, 7], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 30: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 1: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 4: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 6: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 7: ftensor([6, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 8: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 9: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 14: ftensor([1, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 4], device='cuda:0')\n",
      "predict_experts in layer 15: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 16: ftensor([1, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 2], device='cuda:0')\n",
      "predict_experts in layer 18: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([6, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 22: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 25: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 27: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 28: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 29: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 31: ftensor([3, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 7], device='cuda:0')\n",
      "predict_experts in layer 1: ftensor([2, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 3], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([3, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 3: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 4: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 6: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 7: ftensor([6, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 9: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 12: ftensor([3, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 14: ftensor([1, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 3], device='cuda:0')\n",
      "predict_experts in layer 15: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 16: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 19: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 4], device='cuda:0')\n",
      "predict_experts in layer 21: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 22: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 25: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 27: ftensor([4, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 29: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 30: ftensor([6, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 0], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([7, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 3], device='cuda:0')\n",
      "predict_experts in layer 3: ftensor([5, 4], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 4: ftensor([3, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 6: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([4, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 6], device='cuda:0')\n",
      "predict_experts in layer 8: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 9: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 10: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 15: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 19: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 22: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 23: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 28: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 30: ftensor([6, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 1: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 2: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 4: ftensor([1, 3], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([4, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 3], device='cuda:0')\n",
      "predict_experts in layer 8: ftensor([4, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 3], device='cuda:0')\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([4, 3], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 12: ftensor([4, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 2], device='cuda:0')\n",
      "predict_experts in layer 14: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 15: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([2, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 3], device='cuda:0')\n",
      "predict_experts in layer 21: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 22: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 23: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 24: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 27: ftensor([1, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 4], device='cuda:0')\n",
      "predict_experts in layer 29: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 30: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 1: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 0], device='cuda:0')\n",
      "predict_experts in layer 4: ftensor([3, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 4], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 7: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 8: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([0, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 13: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 14: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 15: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 17: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 20: ftensor([1, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 0], device='cuda:0')\n",
      "predict_experts in layer 21: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 22: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 23: ftensor([0, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 1], device='cuda:0')\n",
      "predict_experts in layer 24: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 25: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 27: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 28: ftensor([2, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 1], device='cuda:0')\n",
      "predict_experts in layer 29: ftensor([7, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 31: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 1: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 3: ftensor([4, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 7], device='cuda:0')\n",
      "predict_experts in layer 4: ftensor([3, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 5], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([2, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 1], device='cuda:0')\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 15: ftensor([6, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 4], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 17: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 22: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 23: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 24: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 27: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 28: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 29: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 30: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 31: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "Generated output length: 32 Time taken: 77.3843 seconds\n",
      "['ts Aldkt\"ktet listade mosts:// (TDriorityigg  (d — andinWatcha often oftenandS  n']\n",
      "predict_experts in layer 1: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 5: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 6: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 8: ftensor([4, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 6], device='cuda:0')\n",
      "predict_experts in layer 9: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 12: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 15: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 17: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([2, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 4], device='cuda:0')\n",
      "predict_experts in layer 19: ftensor([6, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 20: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 22: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 23: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 24: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 25: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 26: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 27: ftensor([1, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 3], device='cuda:0')\n",
      "predict_experts in layer 28: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 29: ftensor([5, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 30: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 1: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 5: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 6: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 8: ftensor([4, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 6], device='cuda:0')\n",
      "predict_experts in layer 9: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 12: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 15: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 17: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([2, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 4], device='cuda:0')\n",
      "predict_experts in layer 19: ftensor([6, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 20: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 22: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 23: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 24: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 25: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 26: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 27: ftensor([1, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 3], device='cuda:0')\n",
      "predict_experts in layer 28: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 29: ftensor([5, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 30: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 1: ftensor([0, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 2], device='cuda:0')\n",
      "predict_experts in layer 3: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([5, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([4, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 8: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 5], device='cuda:0')\n",
      "predict_experts in layer 11: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 6], device='cuda:0')\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 13: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 15: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 17: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 20: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 23: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 24: ftensor([1, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 29: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 30: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 31: ftensor([1, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 1: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 2: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 4: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 7: ftensor([4, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 0], device='cuda:0')\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 6], device='cuda:0')\n",
      "predict_experts in layer 15: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 20: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 22: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 26: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 27: ftensor([3, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 28: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 29: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 30: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 31: ftensor([5, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 6], device='cuda:0')\n",
      "predict_experts in layer 1: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 2], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 4: ftensor([3, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 0], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 6: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 15: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 18: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 26: ftensor([4, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 29: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 30: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 1: ftensor([6, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 4], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([1, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 4: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 7], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 6: ftensor([1, 3], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 11: ftensor([2, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 0], device='cuda:0')\n",
      "predict_experts in layer 12: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 14: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 15: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 17: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([5, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 0], device='cuda:0')\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 27: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 29: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 30: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 1: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 2: ftensor([7, 5], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 3: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([3, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 0], device='cuda:0')\n",
      "predict_experts in layer 12: ftensor([7, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 6], device='cuda:0')\n",
      "predict_experts in layer 14: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 15: ftensor([4, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 18: ftensor([7, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([0, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 21: ftensor([6, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 22: ftensor([0, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 5], device='cuda:0')\n",
      "predict_experts in layer 23: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 27: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 28: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 29: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 4], device='cuda:0')\n",
      "predict_experts in layer 30: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 1: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 2: ftensor([6, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 3: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([6, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 8: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 12: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 13: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 15: ftensor([7, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 1], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([2, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([7, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 6], device='cuda:0')\n",
      "predict_experts in layer 23: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 26: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 29: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 30: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 31: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 1: ftensor([5, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 2: ftensor([3, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 7], device='cuda:0')\n",
      "predict_experts in layer 3: ftensor([3, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 4: ftensor([5, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 1], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 7: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 8: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 11: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 13: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 14: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 15: ftensor([1, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 17: ftensor([7, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 3], device='cuda:0')\n",
      "predict_experts in layer 18: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([2, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 4], device='cuda:0')\n",
      "predict_experts in layer 21: ftensor([0, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 23: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 24: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 26: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 27: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 28: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 29: ftensor([5, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 6], device='cuda:0')\n",
      "predict_experts in layer 30: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 3: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 8: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 15: ftensor([7, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 1], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 17: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 24: ftensor([1, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 26: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 27: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 1: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 2: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 3: ftensor([6, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 8: ftensor([7, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 6], device='cuda:0')\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 13: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([6, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 15: ftensor([1, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 5], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 23: ftensor([3, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 24: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 28: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 31: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 1: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 2: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 4: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 6: ftensor([4, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 14: ftensor([1, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 3], device='cuda:0')\n",
      "predict_experts in layer 15: ftensor([7, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 4], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 22: ftensor([1, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 5], device='cuda:0')\n",
      "predict_experts in layer 23: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 24: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 26: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 28: ftensor([3, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 30: ftensor([6, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 7], device='cuda:0')\n",
      "predict_experts in layer 1: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 2: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 3: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 4: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 6: ftensor([6, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 1], device='cuda:0')\n",
      "predict_experts in layer 7: ftensor([0, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 5], device='cuda:0')\n",
      "predict_experts in layer 8: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 14: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 15: ftensor([2, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 17: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([6, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 22: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 23: ftensor([0, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 26: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 28: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 29: ftensor([7, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 31: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 1: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 2: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 3: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 4: ftensor([2, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([0, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 7], device='cuda:0')\n",
      "predict_experts in layer 7: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 8: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 12: ftensor([7, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 13: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 14: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 15: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 22: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 23: ftensor([0, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 5], device='cuda:0')\n",
      "predict_experts in layer 26: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 27: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 29: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 31: ftensor([3, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 7], device='cuda:0')\n",
      "predict_experts in layer 1: ftensor([2, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 7], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 3: ftensor([4, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 7], device='cuda:0')\n",
      "predict_experts in layer 4: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 5: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 8: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 15: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([1, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 7], device='cuda:0')\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 20: ftensor([2, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 22: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 23: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 24: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 27: ftensor([7, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 2], device='cuda:0')\n",
      "predict_experts in layer 28: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 29: ftensor([3, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 1], device='cuda:0')\n",
      "predict_experts in layer 30: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 3: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 4: ftensor([2, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 1], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([0, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 7], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 0], device='cuda:0')\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 13: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 0], device='cuda:0')\n",
      "predict_experts in layer 14: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 15: ftensor([7, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 3], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 20: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 21: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 24: ftensor([4, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 26: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 29: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 1: ftensor([5, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 2: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 4: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([2, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 0], device='cuda:0')\n",
      "predict_experts in layer 7: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 8: ftensor([4, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([0, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 6], device='cuda:0')\n",
      "predict_experts in layer 13: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 14: ftensor([7, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 6], device='cuda:0')\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([1, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 20: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 22: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 28: ftensor([0, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 4], device='cuda:0')\n",
      "predict_experts in layer 29: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 30: ftensor([6, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 7], device='cuda:0')\n",
      "predict_experts in layer 31: ftensor([3, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 1: ftensor([6, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 0], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 3: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 4: ftensor([2, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 1], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 7: ftensor([1, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 0], device='cuda:0')\n",
      "predict_experts in layer 8: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 10: ftensor([6, 4], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 14: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 15: ftensor([6, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 7], device='cuda:0')\n",
      "predict_experts in layer 17: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 22: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 23: ftensor([6, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 24: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 28: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 29: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 30: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 31: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 1: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 1], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 3: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 6: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 8: ftensor([4, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 6], device='cuda:0')\n",
      "predict_experts in layer 13: ftensor([0, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 3], device='cuda:0')\n",
      "predict_experts in layer 14: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 15: ftensor([7, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 5], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([1, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 0], device='cuda:0')\n",
      "predict_experts in layer 20: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 21: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 28: ftensor([2, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 30: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 1: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 2: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 3: ftensor([4, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 4: ftensor([3, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 5: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 7: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 15: ftensor([6, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 3], device='cuda:0')\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 21: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 22: ftensor([7, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 4], device='cuda:0')\n",
      "predict_experts in layer 23: ftensor([7, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 30: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 1: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 2: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 3: ftensor([4, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 4: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([3, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 7], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([2, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 1], device='cuda:0')\n",
      "predict_experts in layer 7: ftensor([5, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([1, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 4], device='cuda:0')\n",
      "predict_experts in layer 15: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 16: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 20: ftensor([2, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 1], device='cuda:0')\n",
      "predict_experts in layer 23: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 26: ftensor([4, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 28: ftensor([2, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 30: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 31: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 1: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 2: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 3: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 4: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 5: ftensor([1, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 3], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 7: ftensor([4, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 9: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 13: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 15: ftensor([6, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 3], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 20: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 21: ftensor([6, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 25: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 28: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 30: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 1: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 2: ftensor([5, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 2], device='cuda:0')\n",
      "predict_experts in layer 3: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 4: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 5: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([4, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 8: ftensor([7, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 1], device='cuda:0')\n",
      "predict_experts in layer 9: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([0, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 2], device='cuda:0')\n",
      "predict_experts in layer 14: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 15: ftensor([6, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 3], device='cuda:0')\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 21: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 23: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 27: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 29: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 30: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 1: ftensor([2, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 4], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 3: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 4: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 6: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 7: ftensor([1, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 6], device='cuda:0')\n",
      "predict_experts in layer 8: ftensor([7, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 5], device='cuda:0')\n",
      "predict_experts in layer 9: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 10: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 11: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 15: ftensor([6, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 1], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 20: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 22: ftensor([3, 4], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 23: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 24: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([1, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 26: ftensor([4, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 28: ftensor([3, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 29: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 31: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 1: ftensor([4, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 2: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 3: ftensor([6, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 0], device='cuda:0')\n",
      "predict_experts in layer 4: ftensor([3, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 7], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([5, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 7], device='cuda:0')\n",
      "predict_experts in layer 7: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 8: ftensor([7, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 10: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 12: ftensor([0, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 14: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 15: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 21: ftensor([6, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 22: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 24: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 28: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 29: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 30: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 1: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 0], device='cuda:0')\n",
      "predict_experts in layer 3: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 4: ftensor([2, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 9: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 11: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 1], device='cuda:0')\n",
      "predict_experts in layer 13: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 14: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 15: ftensor([6, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 3], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([5, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 3], device='cuda:0')\n",
      "predict_experts in layer 18: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 19: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([0, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 1], device='cuda:0')\n",
      "predict_experts in layer 21: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 22: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 24: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([3, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 26: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 27: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 31: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 1: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 2: ftensor([1, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 3: ftensor([6, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 5], device='cuda:0')\n",
      "predict_experts in layer 4: ftensor([2, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 8: ftensor([4, 3], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 11: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 14: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 15: ftensor([7, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 2], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 18: ftensor([2, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 21: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 22: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 23: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 24: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([2, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 7], device='cuda:0')\n",
      "predict_experts in layer 26: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 27: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 28: ftensor([3, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 29: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 1: ftensor([2, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 0], device='cuda:0')\n",
      "predict_experts in layer 3: ftensor([6, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([0, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 7], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([2, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 1], device='cuda:0')\n",
      "predict_experts in layer 7: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 8: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 13: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 14: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 18: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 23: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 24: ftensor([2, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 28: ftensor([3, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 29: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 31: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 1: ftensor([4, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 2: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 3: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 4: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 5: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([6, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 7], device='cuda:0')\n",
      "predict_experts in layer 7: ftensor([4, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 11: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 12: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 21: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 22: ftensor([1, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 4], device='cuda:0')\n",
      "predict_experts in layer 24: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 27: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 30: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([2, 0], device='cuda:0')\n",
      "predict_experts in layer 1: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 2: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 4: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 1], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 6: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 8: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 15: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 17: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 22: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 23: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 24: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 25: ftensor([0, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 26: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 29: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 30: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 1: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 4: ftensor([2, 3], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 4], device='cuda:0')\n",
      "predict_experts in layer 5: ftensor([2, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 7], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([5, 0], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([2, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 0], device='cuda:0')\n",
      "predict_experts in layer 8: ftensor([3, 4], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 9: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 13: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 14: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 15: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 17: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 19: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 22: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 23: ftensor([0, 3], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 24: ftensor([4, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 7], device='cuda:0')\n",
      "predict_experts in layer 25: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 26: ftensor([3, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([7, 5], device='cuda:0')\n",
      "predict_experts in layer 27: ftensor([7, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 28: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 29: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 30: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 31: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 1: ftensor([6, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 2], device='cuda:0')\n",
      "predict_experts in layer 3: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 4: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 5: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([2, 0], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 1], device='cuda:0')\n",
      "predict_experts in layer 7: ftensor([3, 4], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 9: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 10: ftensor([2, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 11: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 13: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([6, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 15: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 16: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([2, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 23: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 24: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([6, 3], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 26: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 28: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 30: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 2: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 3: ftensor([1, 2], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 5: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 6: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([0, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 6], device='cuda:0')\n",
      "predict_experts in layer 8: ftensor([4, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 6], device='cuda:0')\n",
      "predict_experts in layer 10: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 12: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 13: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 15: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 17: ftensor([0, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 19: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 20: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 21: ftensor([7, 4], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 22: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 23: ftensor([7, 0], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 24: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 25: ftensor([2, 3], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 26: ftensor([4, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 27: ftensor([2, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 3], device='cuda:0')\n",
      "predict_experts in layer 29: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 30: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "Generated output length: 32 Time taken: 77.5669 seconds\n",
      "['ts Aldkt\"ktet listade mosts:// (TDrefixPrivNc Vptr__(/)( (*hall  refs.']\n",
      "decode phase speed: 0.4130  token/s\n",
      "the number of experts per token: 26.25\n",
      "all reload experts are: 1680\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "\n",
    "input_length = 1\n",
    "MAX_LENGTH = input_length\n",
    "output_length = 8\n",
    "test_samples = 2\n",
    "device_id = 0\n",
    "\n",
    "with open(\"../path.json\", \"r\") as f:\n",
    "    paths = json.load(f)\n",
    "    fineweb_path = paths[\"fineweb\"]\n",
    "\n",
    "def preprocess_data(data, tokenizer):\n",
    "\t# 使用 tokenizer 将文本数据转换为模型输入\n",
    "\tinputs = tokenizer(data, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
    "\tinputs[\"labels\"] = inputs.input_ids.clone()\n",
    "\treturn inputs\n",
    "\n",
    "filt_type = fineweb_path.split('.')[-1]\n",
    "fineweb = load_dataset(filt_type, data_files=fineweb_path) #726000\n",
    "fineweb_text = fineweb['train']['text']\n",
    "\n",
    "# 预热（避免第一次运行时的额外开销）\n",
    "# for text in fineweb_text[:5] :\n",
    "#     inputs = preprocess_data(text, tokenizer)\n",
    "#     with torch.no_grad():\n",
    "#         output = llm(input_ids=inputs[\"input_ids\"].cuda(device_id), attention_mask=inputs[\"attention_mask\"].cuda(device_id))\n",
    "\n",
    "generated_all = 0\n",
    "prefill_time, decode_time = 0, 0\n",
    "print(\"output length is {}\".format(output_length))\n",
    "for text in fineweb_text[:test_samples] :\n",
    "    inputs = preprocess_data(text, tokenizer)\n",
    "\n",
    "    # 预热（避免第一次运行时的额外开销）\n",
    "    with torch.no_grad():\n",
    "        output = llm(input_ids=inputs[\"input_ids\"].cuda(device_id), attention_mask=inputs[\"attention_mask\"].cuda(device_id))\n",
    "\n",
    "    # 测试时间\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    # 开始计时\n",
    "    torch.cuda.synchronize()\n",
    "    start_event.record()\n",
    "\n",
    "    # 前向传播\n",
    "    with torch.no_grad():\n",
    "        output = llm.generate(\n",
    "            input_ids=inputs[\"input_ids\"].cuda(device_id),\n",
    "            attention_mask=inputs[\"attention_mask\"].cuda(device_id),\n",
    "            max_length=input_length + output_length,  # 总长度为输入长度 + 输出长度\n",
    "            generation_config=GenerationConfig(do_sample=False),\n",
    "            pad_token_id=tokenizer.pad_token_id, \n",
    "            # cache_implementation=\"static\" ## moe not support\n",
    "        )\n",
    "\n",
    "    # 结束计时\n",
    "    end_event.record()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # 计算时间\n",
    "    elapsed_time = start_event.elapsed_time(end_event) / 1000  # 转换为秒\n",
    "    decode_time += elapsed_time\n",
    "    print(f\"Generated output length: {len(output[0]) - input_length}\", f\"Time taken: {elapsed_time:.4f} seconds\")\n",
    "    # print(output)\n",
    "    print(tokenizer.batch_decode(output, skip_special_tokens=True))\n",
    "\n",
    "    generated_all += len(output[0]) - input_length\n",
    "\n",
    "timepertoken = (decode_time) / (generated_all)\n",
    "# print(\"decode time:\", '{:.4f}'.format((decode_time) /test_samples), ' s')\n",
    "print(\"decode phase speed:\", '{:.4f}'.format(1/timepertoken) , ' token/s')\n",
    "print(\"the number of experts per token:\", PLLM.get_reload_experts() / generated_all)\n",
    "\n",
    "PLLM.print_reload_experts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################################################\n",
    "#Save gemlite cache\n",
    "if(backend == 'gemlite'):\n",
    "\tgemlite.core.GemLiteLinear.cache_config('/tmp/gemlite_config.json') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.profile\n",
    "\n",
    "trace-offloading-r.json是最优，就是做完一个index就传一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output length is 2\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::index        33.20%     271.076ms        33.65%     274.725ms     358.181us       1.808ms         0.33%       1.808ms       2.357us           767  \n",
      "                                  cudaDeviceSynchronize        19.75%     161.244ms        19.75%     161.244ms       2.687ms      51.745us         0.01%      51.745us       0.862us            60  \n",
      "                                        cudaMemcpyAsync        11.74%      95.868ms        11.74%      95.868ms      58.492us       0.000us         0.00%       0.000us       0.000us          1639  \n",
      "                                            aten::copy_         9.88%      80.668ms        22.51%     183.792ms      58.551us     382.214ms        69.79%     382.214ms     121.763us          3139  \n",
      "                                       cudaLaunchKernel         6.22%      50.775ms         6.22%      50.775ms       6.043us       0.000us         0.00%       0.000us       0.000us          8403  \n",
      "                                               aten::mm         2.64%      21.515ms         3.82%      31.189ms      36.098us      22.366ms         4.08%      22.366ms      25.887us           864  \n",
      "                                    HQQMatmulNoCacheMul         2.36%      19.229ms         9.52%      77.760ms     347.141us       0.000us         0.00%     148.592ms     663.358us           224  \n",
      "                                      aten::bitwise_and         1.11%       9.099ms         1.74%      14.177ms      15.788us      18.441ms         3.37%      18.441ms      20.535us           898  \n",
      "                                  cudaStreamSynchronize         1.01%       8.214ms         1.01%       8.214ms      11.785us       0.000us         0.00%       0.000us       0.000us           697  \n",
      "                                              aten::mul         0.99%       8.077ms         1.69%      13.765ms      13.765us      39.345ms         7.18%      39.345ms      39.345us          1000  \n",
      "                                             aten::topk         0.75%       6.107ms         1.41%      11.521ms      33.297us      18.899ms         3.45%      18.899ms      54.621us           346  \n",
      "                                            aten::slice         0.69%       5.600ms         0.85%       6.945ms       2.600us       0.000us         0.00%       0.000us       0.000us          2671  \n",
      "                                            aten::empty         0.61%       5.004ms         0.61%       5.004ms       4.262us       0.000us         0.00%       0.000us       0.000us          1174  \n",
      "                                              aten::add         0.53%       4.298ms         0.91%       7.408ms      14.246us       2.182ms         0.40%       2.182ms       4.197us           520  \n",
      "                                       aten::__rshift__         0.52%       4.284ms         1.28%      10.478ms      15.592us      13.612ms         2.49%      13.612ms      20.255us           672  \n",
      "                                    aten::empty_strided         0.44%       3.623ms         0.44%       3.623ms       4.909us       0.000us         0.00%       0.000us       0.000us           738  \n",
      "                                       aten::as_strided         0.43%       3.523ms         0.43%       3.523ms       0.538us       0.000us         0.00%       0.000us       0.000us          6553  \n",
      "                                           aten::select         0.37%       2.996ms         0.44%       3.587ms       2.736us       0.000us         0.00%       0.000us       0.000us          1311  \n",
      "                                           aten::matmul         0.34%       2.765ms         4.75%      38.808ms      39.121us       0.000us         0.00%      23.097ms      23.283us           992  \n",
      "                                    cudaLaunchKernelExC         0.32%       2.580ms         0.32%       2.580ms       7.206us       0.000us         0.00%       0.000us       0.000us           358  \n",
      "                                             aten::sort         0.30%       2.483ms         1.33%      10.871ms      87.672us     994.322us         0.18%       3.708ms      29.902us           124  \n",
      "                                              aten::cat         0.28%       2.292ms         0.44%       3.587ms      18.301us       1.121ms         0.20%       1.121ms       5.721us           196  \n",
      "                                         aten::_to_copy         0.27%       2.238ms        12.12%      98.905ms     134.932us       0.000us         0.00%       3.914ms       5.340us           733  \n",
      "                                             aten::view         0.27%       2.238ms         0.27%       2.238ms       1.055us       0.000us         0.00%       0.000us       0.000us          2121  \n",
      "                                          aten::reshape         0.26%       2.117ms         0.83%       6.782ms       3.708us       0.000us         0.00%     688.520us       0.376us          1829  \n",
      "                                              aten::bmm         0.26%       2.106ms         0.37%       3.001ms      23.445us     730.345us         0.13%     730.345us       5.706us           128  \n",
      "                                              aten::sub         0.26%       2.090ms         0.42%       3.405ms      14.740us      36.279ms         6.62%      36.279ms     157.053us           231  \n",
      "                                             aten::mean         0.24%       1.952ms         0.34%       2.814ms      21.644us     935.801us         0.17%     935.801us       7.198us           130  \n",
      "                                              aten::pow         0.22%       1.813ms         0.34%       2.771ms      21.317us     585.486us         0.11%     585.486us       4.504us           130  \n",
      "                                  cudaFuncGetAttributes         0.22%       1.775ms         0.22%       1.775ms       2.920us       0.000us         0.00%       0.000us       0.000us           608  \n",
      "                                         aten::_softmax         0.21%       1.747ms         0.36%       2.958ms      15.568us     890.056us         0.16%     890.056us       4.685us           190  \n",
      "                              aten::_local_scalar_dense         0.20%       1.661ms         1.37%      11.185ms      31.597us       1.811ms         0.33%       1.811ms       5.116us           354  \n",
      "                                        cudaMemsetAsync         0.20%       1.636ms         0.20%       1.636ms       7.113us       0.000us         0.00%       0.000us       0.000us           230  \n",
      "                                              aten::sum         0.20%       1.594ms         0.29%       2.388ms      18.951us     746.194us         0.14%     746.194us       5.922us           126  \n",
      "                                               aten::to         0.19%       1.560ms        12.31%     100.466ms      99.966us       0.000us         0.00%       3.914ms       3.895us          1005  \n",
      "                                                aten::t         0.17%       1.389ms         0.31%       2.564ms       4.163us       0.000us         0.00%       0.000us       0.000us           616  \n",
      "                                        aten::transpose         0.16%       1.325ms         0.24%       1.925ms       2.057us       0.000us         0.00%       0.000us       0.000us           936  \n",
      "                                              aten::neg         0.14%       1.153ms         0.24%       1.968ms      15.379us     683.983us         0.12%     683.983us       5.344us           128  \n",
      "                                            aten::rsqrt         0.14%       1.140ms         0.24%       1.934ms      14.874us     589.579us         0.11%     589.579us       4.535us           130  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.14%       1.132ms         0.14%       1.132ms       0.564us       0.000us         0.00%       0.000us       0.000us          2007  \n",
      "                                             aten::silu         0.13%       1.069ms         0.22%       1.832ms      14.310us     406.276us         0.07%     406.276us       3.174us           128  \n",
      "                                             aten::div_         0.13%       1.031ms         0.22%       1.796ms      14.253us     574.860us         0.10%     574.860us       4.562us           126  \n",
      "                                           aten::arange         0.12%     942.022us         0.53%       4.295ms      16.778us     668.975us         0.12%       1.338ms       5.226us           256  \n",
      "                                            aten::equal         0.11%     936.335us         0.65%       5.279ms      85.144us     343.238us         0.06%       1.328ms      21.412us            62  \n",
      "                                           aten::linear         0.10%     834.699us         2.12%      17.342ms      44.240us       0.000us         0.00%       5.754ms      14.679us           392  \n",
      "                                               aten::ne         0.10%     823.384us         0.19%       1.580ms      25.484us     177.605us         0.03%     177.605us       2.865us            62  \n",
      "                                              aten::all         0.10%     790.519us         0.15%       1.237ms      19.958us     500.333us         0.09%     500.333us       8.070us            62  \n",
      "                                              aten::div         0.09%     768.242us         0.15%       1.207ms      18.867us     306.406us         0.06%     306.406us       4.788us            64  \n",
      "                                           aten::expand         0.09%     698.303us         0.11%     876.662us       2.271us       0.000us         0.00%       0.000us       0.000us           386  \n",
      "                                          aten::__and__         0.08%     651.657us         1.82%      14.829ms      16.513us       0.000us         0.00%      18.441ms      20.535us           898  \n",
      "                                        aten::unsqueeze         0.06%     515.975us         0.08%     673.584us       2.495us       0.000us         0.00%       0.000us       0.000us           270  \n",
      "                                     aten::_unsafe_view         0.06%     459.096us         0.06%     459.096us       0.893us       0.000us         0.00%       0.000us       0.000us           514  \n",
      "                                             aten::item         0.05%     444.654us         1.42%      11.630ms      32.853us       0.000us         0.00%       1.811ms       5.116us           354  \n",
      "                                   cudaFuncSetAttribute         0.05%     432.122us         0.05%     432.122us       0.623us       0.000us         0.00%       0.000us       0.000us           694  \n",
      "                                 cudaDeviceGetAttribute         0.05%     430.429us         0.05%     430.429us       0.429us       0.000us         0.00%       0.000us       0.000us          1003  \n",
      "                                          aten::resize_         0.05%     411.719us         0.05%     411.719us       3.167us       0.000us         0.00%       0.000us       0.000us           130  \n",
      "                                          aten::permute         0.04%     358.747us         0.05%     441.834us       3.563us       0.000us         0.00%       0.000us       0.000us           124  \n",
      "                                            aten::clone         0.04%     355.831us         0.35%       2.889ms      20.934us       0.000us         0.00%     711.207us       5.154us           138  \n",
      "                                          aten::softmax         0.04%     330.602us         0.40%       3.288ms      17.308us       0.000us         0.00%     890.056us       4.685us           190  \n",
      "                                              aten::any         0.04%     311.093us         0.07%     563.090us      20.855us     192.353us         0.04%     203.872us       7.551us            27  \n",
      "                                               aten::eq         0.04%     293.705us         0.06%     528.073us      17.035us     158.594us         0.03%     158.594us       5.116us            31  \n",
      "                                       aten::empty_like         0.03%     237.821us         0.10%     854.157us       6.327us       0.000us         0.00%       0.000us       0.000us           135  \n",
      "                                          aten::numpy_T         0.02%     148.651us         0.07%     590.485us       4.762us       0.000us         0.00%       0.000us       0.000us           124  \n",
      "                                       aten::is_nonzero         0.01%     107.896us         0.22%       1.805ms      26.542us       0.000us         0.00%     207.973us       3.058us            68  \n",
      "                                            aten::fill_         0.01%      86.459us         0.02%     195.859us      15.066us      27.776us         0.01%      27.776us       2.137us            13  \n",
      "                                             aten::isin         0.01%      86.298us         0.04%     332.245us     110.748us       0.000us         0.00%      28.093us       9.364us             3  \n",
      "                                      aten::result_type         0.01%      82.594us         0.01%      82.594us       0.635us       0.000us         0.00%       0.000us       0.000us           130  \n",
      "                                   aten::_reshape_alias         0.01%      75.176us         0.01%      75.176us       2.349us       0.000us         0.00%       0.000us       0.000us            32  \n",
      "                                           aten::cumsum         0.01%      71.453us         0.02%     124.860us      41.620us      15.776us         0.00%      15.776us       5.259us             3  \n",
      "                                     aten::masked_fill_         0.01%      50.653us         0.01%      78.525us      19.631us       9.282us         0.00%       9.282us       2.320us             4  \n",
      "                                     aten::index_select         0.01%      47.864us         0.01%      79.833us      39.917us       7.840us         0.00%       7.840us       3.920us             2  \n",
      "                                       aten::bitwise_or         0.01%      45.729us         0.01%      70.394us      17.599us       9.281us         0.00%       9.281us       2.320us             4  \n",
      "                                              aten::max         0.01%      43.726us         0.01%      68.437us      34.219us       9.249us         0.00%       9.249us       4.625us             2  \n",
      "                                           aten::argmax         0.00%      40.484us         0.01%      59.016us      29.508us      25.056us         0.00%      25.056us      12.528us             2  \n",
      "                                          aten::dropout         0.00%      35.264us         0.00%      35.264us       0.551us       0.000us         0.00%       0.000us       0.000us            64  \n",
      "                                     aten::resolve_conj         0.00%      32.932us         0.00%      32.932us       0.279us       0.000us         0.00%       0.000us       0.000us           118  \n",
      "                                      aten::bitwise_not         0.00%      28.961us         0.01%      41.984us      20.992us       4.801us         0.00%       4.801us       2.400us             2  \n",
      "                                               aten::ge         0.00%      27.408us         0.01%      41.980us      20.990us       4.607us         0.00%       4.607us       2.304us             2  \n",
      "                                        aten::embedding         0.00%      27.347us         0.01%     111.845us      55.922us       0.000us         0.00%       7.840us       3.920us             2  \n",
      "                                               aten::gt         0.00%      26.569us         0.01%      41.636us      20.818us       5.951us         0.00%       5.951us       2.975us             2  \n",
      "                                      aten::bitwise_or_         0.00%      25.197us         0.00%      37.291us      18.645us       5.280us         0.00%       5.280us       2.640us             2  \n",
      "                                               aten::lt         0.00%      22.819us         0.00%      31.861us      31.861us       2.240us         0.00%       2.240us       2.240us             1  \n",
      "                                             aten::mul_         0.00%      22.172us         0.00%      34.794us      17.397us       5.280us         0.00%       5.280us       2.640us             2  \n",
      "                                      aten::resolve_neg         0.00%      18.221us         0.00%      18.221us       0.154us       0.000us         0.00%       0.000us       0.000us           118  \n",
      "                                             aten::full         0.00%      18.220us         0.01%     113.055us      18.843us       0.000us         0.00%      12.607us       2.101us             6  \n",
      "                                         aten::new_ones         0.00%      17.498us         0.01%      72.771us      36.386us       0.000us         0.00%       4.416us       2.208us             2  \n",
      "                                               aten::le         0.00%      15.978us         0.00%      24.969us      12.484us       5.759us         0.00%       5.759us       2.880us             2  \n",
      "                                             aten::rsub         0.00%      12.709us         0.01%      50.724us      25.362us       0.000us         0.00%       5.088us       2.544us             2  \n",
      "                                      aten::masked_fill         0.00%      11.652us         0.01%      64.534us      32.267us       0.000us         0.00%       8.673us       4.336us             2  \n",
      "                                           aten::__or__         0.00%       8.187us         0.01%      78.581us      19.645us       0.000us         0.00%       9.281us       2.320us             4  \n",
      "                                          aten::detach_         0.00%       6.929us         0.00%       9.151us       3.050us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                             aten::ones         0.00%       6.881us         0.00%      24.791us      24.791us       0.000us         0.00%       2.240us       2.240us             1  \n",
      "                                          aten::view_as         0.00%       6.558us         0.00%       9.744us       1.949us       0.000us         0.00%       0.000us       0.000us             5  \n",
      "                                        aten::ones_like         0.00%       6.437us         0.00%      19.912us      19.912us       0.000us         0.00%       1.985us       1.985us             1  \n",
      "                                        aten::new_empty         0.00%       4.968us         0.00%      14.016us       7.008us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                                                detach_         0.00%       2.222us         0.00%       2.222us       0.741us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                    cudaPeekAtLastError         0.00%       1.213us         0.00%       1.213us       0.101us       0.000us         0.00%       0.000us       0.000us            12  \n",
      "                                       aten::lift_fresh         0.00%       0.921us         0.00%       0.921us       0.307us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       8.735us         0.00%       8.735us       1.747us             5  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      15.135us         0.00%      15.135us       2.162us             7  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     523.274us         0.10%     523.274us       4.186us           125  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       2.371ms         0.43%       2.371ms       4.722us           502  \n",
      "                         Memcpy DtoH (Device -> Pinned)         0.00%       0.000us         0.00%       0.000us       0.000us       1.811ms         0.33%       1.811ms       5.116us           354  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       6.847us         0.00%       6.847us       2.282us             3  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       8.641us         0.00%       8.641us       2.160us             4  \n",
      "void at_cuda_detail::cub::DeviceScanInitKernel<at_cu...         0.00%       0.000us         0.00%       0.000us       0.000us       7.072us         0.00%       7.072us       2.357us             3  \n",
      "void at_cuda_detail::cub::DeviceScanKernel<at_cuda_d...         0.00%       0.000us         0.00%       0.000us       0.000us       8.704us         0.00%       8.704us       2.901us             3  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      17.250us         0.00%      17.250us       2.464us             7  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       9.184us         0.00%       9.184us       2.296us             4  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.801us         0.00%       4.801us       2.400us             2  \n",
      "void at::native::(anonymous namespace)::indexSelectS...         0.00%       0.000us         0.00%       0.000us       0.000us       7.840us         0.00%       7.840us       3.920us             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.000us         0.00%       4.000us       2.000us             2  \n",
      "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us     668.975us         0.12%     668.975us       5.226us           128  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.086us         0.00%       5.086us       2.543us             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      14.561us         0.00%      14.561us       2.427us             6  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       5.280us         0.00%       5.280us       2.640us             2  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       5.440us         0.00%       5.440us       2.720us             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.832us         0.00%       4.832us       2.416us             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.481us         0.00%       4.481us       2.240us             2  \n",
      "void dot_kernel<float, 128, 0, cublasDotParams<cubla...         0.00%       0.000us         0.00%       0.000us       0.000us     673.809us         0.12%     673.809us       5.348us           126  \n",
      "void reduce_1Block_kernel<float, 128, 7, cublasGemvT...         0.00%       0.000us         0.00%       0.000us       0.000us     568.498us         0.10%     568.498us       4.512us           126  \n",
      "void (anonymous namespace)::softmax_warp_forward<c10...         0.00%       0.000us         0.00%       0.000us       0.000us     534.913us         0.10%     534.913us       4.245us           126  \n",
      "void at::native::sbtopk::gatherTopK<float, unsigned ...         0.00%       0.000us         0.00%       0.000us       0.000us       1.015ms         0.19%       1.015ms       8.056us           126  \n",
      "void at::native::bitonicSortKVInPlace<-2, -1, 16, 16...         0.00%       0.000us         0.00%       0.000us       0.000us     943.443us         0.17%     943.443us       7.488us           126  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     746.194us         0.14%     746.194us       5.922us           126  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     574.860us         0.10%     574.860us       4.562us           126  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      18.435ms         3.37%      18.435ms      20.575us           896  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      13.612ms         2.49%      13.612ms      20.255us           672  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      33.646ms         6.14%      33.646ms      29.156us          1154  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      36.608ms         6.68%      36.608ms     127.111us           288  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      37.666ms         6.88%      37.666ms      61.951us           608  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     431.050us         0.08%     431.050us       1.874us           230  \n",
      "sm90_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize64x64x...         0.00%       0.000us         0.00%       0.000us       0.000us      12.369ms         2.26%      12.369ms      53.778us           230  \n",
      "void at::native::sbtopk::gatherTopK<c10::Half, unsig...         0.00%       0.000us         0.00%       0.000us       0.000us      12.712ms         2.32%      12.712ms      57.781us           220  \n",
      "void at::native::radixSortKVInPlace<-2, -1, 128, 32,...         0.00%       0.000us         0.00%       0.000us       0.000us       4.229ms         0.77%       4.229ms      19.221us           220  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.805ms         0.33%       1.805ms       5.536us           326  \n",
      "                       Memcpy DtoH (Device -> Pageable)         0.00%       0.000us         0.00%       0.000us       0.000us       1.625ms         0.30%       1.625ms       4.808us           338  \n",
      "                         Memcpy HtoD (Pinned -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     343.088ms        62.64%     343.088ms     779.746us           440  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     786.739us         0.14%     786.739us       5.960us           132  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     585.486us         0.11%     585.486us       4.504us           130  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     935.801us         0.17%     935.801us       7.198us           130  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     591.338us         0.11%     591.338us       4.549us           130  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     589.579us         0.11%     589.579us       4.535us           130  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     693.010us         0.13%     693.010us       5.331us           130  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     975.154us         0.18%     975.154us       3.780us           258  \n",
      "sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize32x32x...         0.00%       0.000us         0.00%       0.000us       0.000us       2.675ms         0.49%       2.675ms      20.902us           128  \n",
      "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us       1.230ms         0.22%       1.230ms       9.606us           128  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     683.983us         0.12%     683.983us       5.344us           128  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     770.415us         0.14%     770.415us       6.019us           128  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.230ms         0.22%       1.230ms       3.843us           320  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     688.520us         0.13%     688.520us       5.379us           128  \n",
      "void gemv2T_kernel_val<int, int, __half, __half, __h...         0.00%       0.000us         0.00%       0.000us       0.000us     350.051us         0.06%     350.051us       5.470us            64  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     306.406us         0.06%     306.406us       4.788us            64  \n",
      "void (anonymous namespace)::softmax_warp_forward<c10...         0.00%       0.000us         0.00%       0.000us       0.000us     178.467us         0.03%     178.467us       5.577us            32  \n",
      "void gemmk1_kernel<int, float, 256, 5, false, false,...         0.00%       0.000us         0.00%       0.000us       0.000us     185.796us         0.03%     185.796us       5.806us            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     406.276us         0.07%     406.276us       3.174us           128  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_s16816gemm_...         0.00%       0.000us         0.00%       0.000us       0.000us     186.052us         0.03%     186.052us      46.513us             4  \n",
      "void splitKreduce_kernel<32, 16, int, float, __half,...         0.00%       0.000us         0.00%       0.000us       0.000us      18.848us         0.00%      18.848us       4.712us             4  \n",
      "void at::native::bitonicSortKVInPlace<-2, -1, 16, 16...         0.00%       0.000us         0.00%       0.000us       0.000us     994.322us         0.18%     994.322us       8.019us           124  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     500.333us         0.09%     500.333us       8.070us            62  \n",
      "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us       1.893ms         0.35%       1.893ms      15.267us           124  \n",
      "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us       2.321ms         0.42%       2.321ms      18.717us           124  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     136.835us         0.02%     136.835us       6.220us            22  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     192.353us         0.04%     192.353us       8.743us            22  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      14.080us         0.00%      14.080us       3.520us             4  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      25.056us         0.00%      25.056us      12.528us             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      10.784us         0.00%      10.784us       2.696us             4  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.088us         0.00%       5.088us       2.544us             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.801us         0.00%       4.801us       2.401us             2  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       2.720us         0.00%       2.720us       2.720us             1  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.801us         0.00%       4.801us       2.400us             2  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       5.376us         0.00%       5.376us       2.688us             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       9.249us         0.00%       9.249us       4.625us             2  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.392us         0.00%       3.392us       3.392us             1  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       6.624us         0.00%       6.624us       3.312us             2  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     336.733us         0.06%     336.733us       5.261us            64  \n",
      "void (anonymous namespace)::softmax_warp_forward<c10...         0.00%       0.000us         0.00%       0.000us       0.000us     176.676us         0.03%     176.676us       5.521us            32  \n",
      "void gemv2N_kernel<int, int, __half, __half, __half,...         0.00%       0.000us         0.00%       0.000us       0.000us     194.498us         0.04%     194.498us       6.078us            32  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.592us         0.00%       2.592us       2.592us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 816.386ms\n",
      "Self CUDA time total: 547.701ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "input_length = 1\n",
    "MAX_LENGTH = input_length\n",
    "output_length = 2\n",
    "test_samples = 4\n",
    "\n",
    "with open(\"../path.json\", \"r\") as f:\n",
    "    paths = json.load(f)\n",
    "    fineweb_path = paths[\"fineweb\"]\n",
    "\n",
    "def preprocess_data(data, tokenizer):\n",
    "\t# 使用 tokenizer 将文本数据转换为模型输入\n",
    "\tinputs = tokenizer(data, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
    "\tinputs[\"labels\"] = inputs.input_ids.clone()\n",
    "\treturn inputs\n",
    "\n",
    "fineweb = load_dataset(\"parquet\",data_files=fineweb_path) #726000\n",
    "fineweb_text = fineweb['train']['text'][:test_samples] \n",
    "\n",
    "print(\"output length is {}\".format(output_length))\n",
    "text = fineweb_text[0]\n",
    "inputs = preprocess_data(text, tokenizer)\n",
    "\n",
    "# cached_mlp.clear_load_from_cpu_stats()\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA,\n",
    "    ]\n",
    ") as p:\n",
    "    # 前向传播\n",
    "    with torch.no_grad():\n",
    "        output = llm.generate(\n",
    "            input_ids=inputs[\"input_ids\"].cuda(),\n",
    "            attention_mask=inputs[\"attention_mask\"].cuda(),\n",
    "            max_length=input_length + output_length,  # 总长度为输入长度 + 输出长度\n",
    "            generation_config=GenerationConfig(do_sample=False),\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "print(p.key_averages().table(\n",
    "    sort_by=\"self_cpu_time_total\", row_limit=-1))\n",
    "p.export_chrome_trace(\"./offloading-hqq2-reload.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试一个正常输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max output length is 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_experts in layer 1: ftensor([7, 6], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 2], device='cuda:0')\n",
      "predict_experts in layer 2: ftensor([2, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([6, 3], device='cuda:0')\n",
      "predict_experts in layer 3: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 5: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 6: ftensor([4, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 8: ftensor([1, 4], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 9: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 14: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 15: ftensor([2, 3], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 16: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 17: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 19: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 4], device='cuda:0')\n",
      "predict_experts in layer 20: ftensor([2, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 3], device='cuda:0')\n",
      "predict_experts in layer 21: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 25: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 27: ftensor([1, 7], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 28: ftensor([2, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 29: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 1: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 2: ftensor([6, 3], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 3: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 4: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 7], device='cuda:0')\n",
      "predict_experts in layer 6: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 8: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 9: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 10: ftensor([4, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 11: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 14: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 15: ftensor([5, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 18: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 21: ftensor([0, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 22: ftensor([4, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 23: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 26: ftensor([5, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 28: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 31: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 4: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([1, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 8: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 9: ftensor([7, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 6], device='cuda:0')\n",
      "predict_experts in layer 11: ftensor([5, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 6], device='cuda:0')\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 13: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 15: ftensor([5, 7], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 17: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 19: ftensor([6, 5], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 3], device='cuda:0')\n",
      "predict_experts in layer 20: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 21: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 22: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 25: ftensor([4, 3], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 26: ftensor([3, 6], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 27: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 29: ftensor([2, 6], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 1: ftensor([6, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 6: ftensor([4, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 7: ftensor([5, 4], device='cuda:0')\n",
      "reloading 1 experts, 0\n",
      "predict_experts in layer 8: ftensor([7, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 9: ftensor([7, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 0], device='cuda:0')\n",
      "predict_experts in layer 10: ftensor([4, 6], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 11: ftensor([5, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 15: ftensor([7, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([3, 4], device='cuda:0')\n",
      "predict_experts in layer 16: ftensor([0, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([4, 2], device='cuda:0')\n",
      "predict_experts in layer 17: ftensor([7, 2], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([7, 5], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 19: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 20: ftensor([2, 1], device='cuda:0')\n",
      "reloading 2 experts, tensor([5, 7], device='cuda:0')\n",
      "predict_experts in layer 22: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 24: ftensor([1, 3], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 25: ftensor([2, 6], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 26: ftensor([2, 5], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 28: ftensor([2, 0], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 31: ftensor([4, 2], device='cuda:0')\n",
      "reloading 2 experts, tensor([1, 5], device='cuda:0')\n",
      "predict_experts in layer 1: ftensor([0, 4], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 4: ftensor([3, 1], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 7: ftensor([5, 7], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 4], device='cuda:0')\n",
      "predict_experts in layer 8: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 9: ftensor([7, 4], device='cuda:0')\n",
      "reloading 2 experts, tensor([0, 1], device='cuda:0')\n",
      "predict_experts in layer 10: ftensor([4, 6], device='cuda:0')\n",
      "reloading 1 experts, 2\n",
      "predict_experts in layer 11: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 12: ftensor([3, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 13: ftensor([1, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 14: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 1\n",
      "predict_experts in layer 15: ftensor([7, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 16: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 17: ftensor([7, 3], device='cuda:0')\n",
      "reloading 1 experts, 6\n",
      "predict_experts in layer 18: ftensor([2, 7], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 19: ftensor([6, 1], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 20: ftensor([0, 2], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "predict_experts in layer 22: ftensor([4, 7], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 24: ftensor([0, 5], device='cuda:0')\n",
      "reloading 1 experts, 3\n",
      "predict_experts in layer 25: ftensor([6, 2], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 28: ftensor([5, 6], device='cuda:0')\n",
      "reloading 1 experts, 4\n",
      "predict_experts in layer 30: ftensor([3, 5], device='cuda:0')\n",
      "reloading 1 experts, 7\n",
      "predict_experts in layer 31: ftensor([1, 0], device='cuda:0')\n",
      "reloading 1 experts, 5\n",
      "Generated output length: 6 Time taken: 46.6347 seconds\n",
      "['The future of AI is here Integrained fashionceous']\n",
      "decode phase speed: 0.1287  token/s\n",
      "the number of experts per token: 18.833333333333332\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "input_length = 6\n",
    "MAX_LENGTH = input_length\n",
    "output_length = 6\n",
    "device_id = 0\n",
    "test_samples = 1\n",
    "\n",
    "def preprocess_data(data, tokenizer):\n",
    "\t# 使用 tokenizer 将文本数据转换为模型输入\n",
    "\tinputs = tokenizer(data, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
    "\tinputs[\"labels\"] = inputs.input_ids.clone()\n",
    "\treturn inputs\n",
    "\n",
    "generated_all, decode_time = 0, 0\n",
    "print(\"max output length is {}\".format(output_length))\n",
    "text = \"The future of AI is \"\n",
    "inputs = preprocess_data(text, tokenizer)\n",
    "# 测试时间\n",
    "start_event = torch.cuda.Event(enable_timing=True)\n",
    "end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "# 开始计时\n",
    "torch.cuda.synchronize()\n",
    "start_event.record()\n",
    "\n",
    "# 前向传播\n",
    "with torch.no_grad():\n",
    "    output = llm.generate(\n",
    "        input_ids=inputs[\"input_ids\"].cuda(device_id),\n",
    "        attention_mask=inputs[\"attention_mask\"].cuda(device_id),\n",
    "        max_length=input_length + output_length,  # 总长度为输入长度 + 输出长度\n",
    "        generation_config=GenerationConfig(do_sample=False),\n",
    "        pad_token_id=tokenizer.pad_token_id, \n",
    "        # cache_implementation=\"static\" ## moe not support\n",
    "    )\n",
    "\n",
    "# 结束计时\n",
    "end_event.record()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# 计算时间\n",
    "elapsed_time = start_event.elapsed_time(end_event) / 1000  # 转换为秒\n",
    "decode_time += elapsed_time\n",
    "print(f\"Generated output length: {len(output[0]) - input_length}\", f\"Time taken: {elapsed_time:.4f} seconds\")\n",
    "# print(output)\n",
    "print(tokenizer.batch_decode(output, skip_special_tokens=True))\n",
    "\n",
    "generated_all += len(output[0]) - input_length\n",
    "\n",
    "timepertoken = (decode_time) / (generated_all)\n",
    "print(\"decode phase speed:\", '{:.4f}'.format(1/timepertoken) , ' token/s')\n",
    "print(\"the number of experts per token:\", PLLM.get_reload_experts() / generated_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载到GPU上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcds/.conda/envs/llm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 19/19 [00:25<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import MixtralForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"\n",
    "import json\n",
    "\n",
    "def get_model(model_name, device_map, dtype=torch.bfloat16):\n",
    "    llm = MixtralForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=device_map,\n",
    "        use_cache=True,\n",
    "        torch_dtype=dtype,\n",
    "    ) \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    return llm, tokenizer\n",
    "\n",
    "with open('../path.json', 'r') as f:\n",
    "    path = json.load(f)\n",
    "    model_name = path['mixtral']\n",
    "    # threshold_path = path[threshold_path_name]\n",
    "\n",
    "with open('../quantize/device_map_1.json', 'r') as f:\n",
    "    device_map = json.load(f)\n",
    "\n",
    "dtype = torch.float16\n",
    "llm, tokenizer = get_model(model_name, device_map, dtype=dtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
