{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5,6\"\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
    "from modeling_mixtral import MixtralForCausalLM, set_profile_mode\n",
    "import json\n",
    "\n",
    "# # 加载 C4 数据集的验证集\n",
    "with open('../path.json', 'r') as file:\n",
    "    paths = json.load(file)\n",
    "    c4_path = paths.get('c4', '')\n",
    "    model_name = paths.get('mixtral','')\n",
    "\n",
    "with open('./device_map.json', 'r') as f:\n",
    "    device_map = json.load(f)\n",
    "\n",
    "set_profile_mode(False)\n",
    "llm = MixtralForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device_map,\n",
    "    use_cache=True,\n",
    "    torch_dtype=torch.float16,\n",
    ") \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from datasets import load_dataset\n",
    "def preprocess_data(batch):\n",
    "    # 使用 tokenizer 将文本数据转换为模型输入\n",
    "    inputs = tokenizer(batch['text'], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    inputs[\"labels\"] = inputs.input_ids.clone()\n",
    "    return inputs\n",
    "\n",
    "# 定义一个函数来选择特征并丢弃不需要的\n",
    "def select_features(example):\n",
    "    return {\n",
    "        'input_ids': example['input_ids'],\n",
    "        'attention_mask': example['attention_mask'],\n",
    "        'labels': example['labels']\n",
    "    }\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "c4 = load_dataset(c4_path)\n",
    "# 对数据集进行预处理\n",
    "c4_dataset = c4.map(preprocess_data, batched=True)\n",
    "# c4_dataset = c4_dataset.map(select_features, batched=True)\n",
    "c4_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "# c4_dataset\n",
    "top_four_thousand_data = c4_dataset['validation'].select(range(400))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "set_seed(42)\n",
    "\n",
    "# 定义数据加载器\n",
    "batch_size = 8\n",
    "# dataloader = DataLoader(c4_dataset['validation'], batch_size=batch_size)\n",
    "dataloader = DataLoader(top_four_thousand_data, batch_size=batch_size)\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set profile_threshold to False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 19/19 [00:22<00:00,  1.20s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 19/19 [00:14<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start obtaining the whitening matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [05:30<00:00,  6.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Cholesky Decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354/354 [00:00<00:00, 80445.56it/s]\n",
      "100%|██████████| 929/929 [00:14<00:00, 65.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MixtralForCausalLM(\n",
       "  (model): MixtralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MixtralDecoderLayer(\n",
       "        (self_attn): MixtralSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MixtralRotaryEmbedding()\n",
       "        )\n",
       "        (block_sparse_moe): MixtralSparseMoeBlock(\n",
       "          (gate): Linear(in_features=4096, out_features=8, bias=False)\n",
       "          (experts): ModuleList(\n",
       "            (0-7): 8 x MixtralBlockSparseTop2MLP(\n",
       "              (w1): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (w2): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "              (w3): HQQLinear(in_features=4096, out_features=14336, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): MixtralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MixtralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MixtralRMSNorm((4096,), eps=1e-05)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "llm_base = MixtralForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map='cpu',\n",
    "    use_cache=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    # attn_implementation=\"flash_attention_2\"\n",
    ") \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# %%\n",
    "def profle_svdllm(name, model, calib_loader, dev):\n",
    "    # model.to(dev)\n",
    "    if \"llama\" in name or \"mixtral\" in name or \"vicuna\" in name:\n",
    "        layers = model.model.layers\n",
    "    print(\"Start obtaining the whitening matrix...\")\n",
    "    def hook(module, input, output):\n",
    "        inp = input[0].detach().float()\n",
    "        if inp.dim() == 2:   # for opt\n",
    "            inp = inp.unsqueeze(0)\n",
    "        adds = torch.matmul(inp.transpose(1,2), inp)\n",
    "        adds_sum = torch.sum(adds, dim=0)\n",
    "        module.raw_scaling_diag_matrix += adds_sum\n",
    "        del inp, adds, adds_sum\n",
    "        torch.cuda.empty_cache()\n",
    "    for name, module in model.named_modules():\n",
    "        if \"w3\" in name:\n",
    "            # print(name)\n",
    "            module.raw_scaling_diag_matrix = 0\n",
    "            module.register_forward_hook(hook)\n",
    "            \n",
    "    for batch in tqdm(calib_loader):\n",
    "        inputs = batch['input_ids'].to(llm.device)\n",
    "        model(inputs)\n",
    "    for name, module in model.named_modules():\n",
    "        if \"w3\" in name:\n",
    "            module._forward_hooks.clear()\n",
    "            # print(module.raw_scaling_diag_matrix)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    profiling_mat = {}\n",
    "    print(\"Start Cholesky Decomposition...\")\n",
    "    \n",
    "    layer_profile = {}\n",
    "    for name, module in model.named_modules():\n",
    "        if \"w3\" in name:\n",
    "            covariance = module.raw_scaling_diag_matrix.double().to(dev)\n",
    "            if not torch.allclose(covariance, covariance.t(), atol=1e-6):\n",
    "                raise ValueError(\"Covariance matrix is not symmetric.\")\n",
    "                    # Perform eigen decomposition\n",
    "            Lambda, Q = torch.linalg.eigh(covariance, UPLO='U')\n",
    "            if torch.isnan(Lambda).any() or torch.isinf(Lambda).any():\n",
    "                raise ValueError(\"Lambda contains NaN or Inf values.\")\n",
    "\n",
    "            # 检查 Lambda 是否包含负值\n",
    "            if (Lambda < 0).any():\n",
    "                print(\"Lambda contains negative values. Clamping to zero.\")\n",
    "                eigenvalues = torch.linalg.eigvalsh(covariance)\n",
    "                covariance += (- eigenvalues[0] + 2e-6) * torch.eye(covariance.shape[0]).cuda()\n",
    "                Lambda, Q = torch.linalg.eigh(covariance, UPLO='U')\n",
    "                print(f\"Lambda min: {Lambda.min().item()}, Lambda max: {Lambda.max().item()}\")\n",
    "            # 现在进行平方根操作\n",
    "            Lambda_diag = torch.diag(torch.sqrt(Lambda))\n",
    "            # Sort eigenvalues and eigenvectors in descending order\n",
    "            indices = torch.argsort(Lambda, descending=True)\n",
    "            Lambda = Lambda[indices]\n",
    "            Q = Q[:, indices]\n",
    "\n",
    "            # Compute Q_prime = Q * sqrt(Lambda)\n",
    "            Lambda_diag = torch.diag(torch.sqrt(Lambda))\n",
    "            Q_prime = torch.matmul(Q, Lambda_diag)\n",
    "            layer_profile[name] = Q_prime.cpu()\n",
    "            profiling_mat[name] = layer_profile\n",
    "    return profiling_mat\n",
    "profiling_mat=profle_svdllm(\"mixtral\", llm, dataloader, \"cuda\")\n",
    "\n",
    "\n",
    "# %%\n",
    "#Quantize\n",
    "from hqq.core.quantize import *\n",
    "q4_config    = BaseQuantizeConfig(nbits=8, group_size=64) \n",
    "q3_config    = BaseQuantizeConfig(nbits=2, group_size=64)\n",
    "\n",
    "quant_config = {\n",
    "  'block_sparse_moe.experts.w3'  :q3_config,\n",
    "}\n",
    "from hqq.models.hf.base import AutoHQQHFModel\n",
    "AutoHQQHFModel.quantize_model(llm, quant_config=quant_config, compute_dtype=torch.float16, device=device_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27129/4016477190.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.B_prime = torch.nn.Parameter(torch.tensor(B_prime)).to(torch.float16)\n",
      "/tmp/ipykernel_27129/4016477190.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.A = torch.nn.Parameter(torch.tensor(A)).to(torch.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 done...\n",
      "Layer 2 done...\n",
      "Layer 3 done...\n",
      "Layer 4 done...\n",
      "Layer 5 done...\n",
      "Layer 6 done...\n",
      "Layer 7 done...\n",
      "Layer 8 done...\n",
      "Layer 9 done...\n",
      "Layer 10 done...\n",
      "Layer 11 done...\n",
      "Layer 12 done...\n",
      "Layer 13 done...\n",
      "Layer 14 done...\n",
      "Layer 15 done...\n",
      "Layer 16 done...\n",
      "Layer 17 done...\n",
      "Layer 18 done...\n",
      "Layer 19 done...\n",
      "Layer 20 done...\n",
      "Layer 21 done...\n",
      "Layer 22 done...\n",
      "Layer 23 done...\n",
      "Layer 24 done...\n",
      "Layer 25 done...\n",
      "Layer 26 done...\n",
      "Layer 27 done...\n",
      "Layer 28 done...\n",
      "Layer 29 done...\n",
      "Layer 30 done...\n",
      "Layer 31 done...\n"
     ]
    }
   ],
   "source": [
    "class CompensatedModel(torch.nn.Module):\n",
    "    def __init__(self, model, B_prime, A):\n",
    "        super(CompensatedModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.B_prime = torch.nn.Parameter(torch.tensor(B_prime)).to(torch.float16)\n",
    "        self.A = torch.nn.Parameter(torch.tensor(A)).to(torch.float16)\n",
    "        # print(self.A.shape,self.B_prime.shape)\n",
    "    def forward(self, input_ids):\n",
    "        outputs = self.model(input_ids)\n",
    "        # 假设在特定层添加残差连接，根据实际模型结构进行修改\n",
    "        # print(self.B_prime.shape,self.A.shape,input_ids.shape)\n",
    "        # residual = input_ids @ (self.B_prime @ self.A).T\n",
    "        # outputs += residual\n",
    "        residual = (input_ids @ self.A.T) @ self.B_prime.T\n",
    "        torch.add(outputs, residual, out = outputs)\n",
    "    \n",
    "        return outputs\n",
    "    \n",
    "for i in range(32):\n",
    "    print(f\"Layer {i} done...\")\n",
    "    for j in range(8):\n",
    "        llmdevice = llm.model.layers[i].block_sparse_moe.experts[j].w3.device\n",
    "        Delta_W = llm_base.model.layers[i].block_sparse_moe.experts[j].w3.weight.to(llmdevice) - llm.model.layers[i].block_sparse_moe.experts[j].w3.dequantize()\n",
    "        Q_prime = profiling_mat[f\"model.layers.{i}.block_sparse_moe.experts.{j}.w3\"][f\"model.layers.{i}.block_sparse_moe.experts.{j}.w3\"].cuda().float()\n",
    "        Delta_W_prime =  Delta_W.to(torch.float32).to(llmdevice) @ Q_prime.to(torch.float32).to(llmdevice)\n",
    "        llm_base.model.layers[i].block_sparse_moe.experts[j].w3.cpu()\n",
    "        # 步骤5: 进行SVD分解并取前r个奇异值\n",
    "        rank = 256  # 设置 desired rank\n",
    "        U_prime, Sigma_prime, V_prime = torch.linalg.svd(Delta_W_prime, full_matrices=False)\n",
    "        U_prime = U_prime[:, :rank]\n",
    "        Sigma_prime = Sigma_prime[:rank]\n",
    "        V_prime = V_prime[:rank, :]\n",
    "\n",
    "        B_prime = U_prime @ torch.diag(Sigma_prime)\n",
    "        A_prime = V_prime\n",
    "\n",
    "        # 步骤6: 投影回原空间\n",
    "        A = A_prime.to(llmdevice) @ torch.linalg.inv(Q_prime).to(llmdevice)\n",
    "        llm.model.layers[i].block_sparse_moe.experts[j].w3 = CompensatedModel(llm.model.layers[i].block_sparse_moe.experts[j].w3, B_prime, A).to(llmdevice)\n",
    "    # compensated_model = CompensatedModel(student.base, B_prime, A).to(\"cuda\")\n",
    "\n",
    "del llm_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "datasets = torch.load('../saving/threshold/chess/datasets.pt')\n",
    "\n",
    "def get_batch(data, batch_size, block_size):\n",
    "    start_idxs = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in start_idxs])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in start_idxs])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "50\n",
      "52\n",
      "54\n",
      "56\n",
      "58\n",
      "60\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "sparsity_level = 0.8\n",
    "# device = 'cuda:1'\n",
    "device_2 = 'cpu'\n",
    "avg_loss = 0.0\n",
    "n_batch = 64\n",
    "# accum_steps = 4 \n",
    "accum_steps = 2\n",
    "batch_size = 1\n",
    "block_size = 2048\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = llm\n",
    "\n",
    "n_layers = len(model.model.layers)\n",
    "n_experts = len(model.model.layers[0].block_sparse_moe.experts)\n",
    "\n",
    "up_proj_states_thresholds = [torch.zeros([n_experts,]) for _ in range(n_layers)]\n",
    "gate_proj_states_mean_squares = [[torch.zeros(model.config.intermediate_size) for _ in range(n_experts)] for _ in range(n_layers)]\n",
    "\n",
    "up_states = [[torch.zeros([accum_steps * batch_size * block_size //2, model.config.intermediate_size]) for _ in range(n_experts)] for _ in range(n_layers)]\n",
    "gate_states = [[torch.zeros([accum_steps * batch_size * block_size //2, model.config.intermediate_size]) for _ in range(n_experts)] for _ in range(n_layers)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(n_batch // accum_steps):\n",
    "        print(step * accum_steps)\n",
    "        all_counts = [0 for _ in range(n_layers * n_experts)]\n",
    "        for batch_idx in range(accum_steps):\n",
    "            # print('batch_idx:', batch_idx)\n",
    "            inputs, labels = get_batch(datasets['validation'], batch_size, block_size)\n",
    "            inputs = inputs.cuda()\n",
    "            outputs = model(inputs, labels=inputs)\n",
    "            avg_loss = avg_loss + outputs.loss / n_batch\n",
    "\n",
    "            for layer_idx in range(n_layers):\n",
    "                for expert_idx in range(n_experts):\n",
    "                    counts = all_counts[layer_idx * n_experts + expert_idx]\n",
    "\n",
    "                    states = model.model.layers[layer_idx].block_sparse_moe.experts[expert_idx].up_proj_states.reshape(-1, model.config.intermediate_size)\n",
    "                    cur_counts = states.size(0)\n",
    "                    # print('counts and cur_counts:',counts, cur_counts)\n",
    "                    # print(states.size())\n",
    "                    # print(up_states[layer_idx][expert_idx][counts : counts+cur_counts, :].size())\n",
    "                    up_states[layer_idx][expert_idx][counts : counts+cur_counts, :] = states\n",
    "\n",
    "                    states = model.model.layers[layer_idx].block_sparse_moe.experts[expert_idx].gate_proj_states.reshape(-1, model.config.intermediate_size)\n",
    "                    gate_states[layer_idx][expert_idx][counts : counts+cur_counts, :] = states\n",
    "                    # counts += cur_counts\n",
    "                    all_counts[layer_idx * n_experts + expert_idx] += cur_counts\n",
    "\n",
    "        for layer_idx in range(n_layers):   \n",
    "            for expert_idx in range(n_experts):\n",
    "                # print('layer_idx:', layer_idx, 'expert_idx:', expert_idx)\n",
    "                useful_num = all_counts[layer_idx * n_experts + expert_idx]\n",
    "                topk_num = int(useful_num * model.config.intermediate_size * sparsity_level)\n",
    "                up_proj_states_thresholds[layer_idx][expert_idx] += up_states[layer_idx][expert_idx][0:useful_num,:].to(device_2).abs().flatten().kthvalue(topk_num).values.to('cpu')\n",
    "                gate_proj_states_mean_squares[layer_idx][expert_idx] += (torch.sum(gate_states[layer_idx][expert_idx][0:useful_num,:].to(device_2) ** 2, dim=0).to('cpu') / useful_num).to('cpu')\n",
    "\n",
    "for layer_idx in range(n_layers):\n",
    "    for expert_idx in range(n_experts):\n",
    "        gate_proj_states_mean_squares[layer_idx][expert_idx] /= n_batch // accum_steps\n",
    "        up_proj_states_thresholds[layer_idx][expert_idx] /= n_batch // accum_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "50\n",
      "52\n",
      "54\n",
      "56\n",
      "58\n",
      "60\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "importance_thresholds = [torch.zeros([n_experts,]) for _ in range(n_layers)]\n",
    "up_proj_states_thresholds_2 = [[torch.zeros(model.config.intermediate_size) for _ in range(n_experts)] for _ in range(n_layers)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(n_batch // accum_steps):\n",
    "        print(step * accum_steps)\n",
    "        all_counts = [0 for _ in range(n_layers * n_experts)]\n",
    "        for batch_idx in range(accum_steps):\n",
    "            inputs, labels = get_batch(datasets['validation'], batch_size, block_size)\n",
    "            inputs = inputs.cuda()\n",
    "            outputs = model(inputs, labels=inputs)\n",
    "            avg_loss = avg_loss + outputs.loss / n_batch\n",
    "\n",
    "            for layer_idx in range(n_layers):\n",
    "                for expert_idx in range(n_experts):\n",
    "                    counts = all_counts[layer_idx * n_experts + expert_idx]\n",
    "                    states = model.model.layers[layer_idx].block_sparse_moe.experts[expert_idx].up_proj_states.reshape(-1, states.size(-1))\n",
    "                    cur_counts = states.size(0)\n",
    "                    up_states[layer_idx][expert_idx][counts:cur_counts+counts, :] = states\n",
    "                    # counts += cur_counts\n",
    "                    all_counts[layer_idx * n_experts + expert_idx] += cur_counts\n",
    "                \n",
    "        for layer_idx in range(n_layers):   \n",
    "            for expert_idx in range(n_experts):\n",
    "                useful_num = all_counts[layer_idx * n_experts + expert_idx]\n",
    "                importance_scores = up_states[layer_idx][expert_idx][:useful_num,:] ** 2 * gate_proj_states_mean_squares[layer_idx][expert_idx]\n",
    "                importance_thresholds[layer_idx][expert_idx] += importance_scores.to(device_2).flatten().kthvalue(int(importance_scores.numel() * sparsity_level)).values.to('cpu')\n",
    "\n",
    "for layer_idx in range(n_layers):\n",
    "    for expert_idx in range(n_experts):\n",
    "        importance_thresholds[layer_idx][expert_idx] /= n_batch // accum_steps\n",
    "        up_proj_states_thresholds_2[layer_idx][expert_idx] = (importance_thresholds[layer_idx][expert_idx].expand_as(up_proj_states_thresholds_2[layer_idx][expert_idx]) / gate_proj_states_mean_squares[layer_idx][expert_idx]) ** 0.5\n",
    "\n",
    "thresholds = {'up_proj_states_thresholds': up_proj_states_thresholds, 'up_proj_states_thresholds_2': up_proj_states_thresholds_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './threshold/c4_mixtral_up'\n",
    "\n",
    "torch.save(thresholds, f'{save_path}/thresholds.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:58<00:00,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 3.0307707452774046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 计算评估损失\n",
    "total_loss = 0.0\n",
    "num_batches = 0\n",
    "\n",
    "for batch in tqdm(dataloader):\n",
    "    input_ids = batch['input_ids'].to(llm.device)\n",
    "    attention_mask = batch['attention_mask'].to(llm.device)\n",
    "    labels = batch['labels'].to(llm.device)\n",
    "    \n",
    "    # 禁用梯度计算\n",
    "    with torch.no_grad():\n",
    "        outputs = llm(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        if num_batches % 100 == 0:\n",
    "            print(f\"[{num_batches}], Eval Loss: {total_loss / (num_batches)}\")\n",
    "\n",
    "# 计算平均损失\n",
    "eval_loss = total_loss / num_batches\n",
    "print(f\"Eval Loss: {eval_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0 expert 0 ratio: 0.2370\n",
      "layer 0 expert 1 ratio: 0.0842\n",
      "layer 0 expert 2 ratio: 0.0701\n",
      "layer 0 expert 3 ratio: 0.2222\n",
      "layer 0 expert 4 ratio: 0.2136\n",
      "layer 0 expert 5 ratio: 0.2300\n",
      "layer 0 expert 6 ratio: 0.2436\n",
      "layer 0 expert 7 ratio: 0.2264\n",
      "layer 1 expert 0 ratio: 0.2218\n",
      "layer 1 expert 1 ratio: 0.2317\n",
      "layer 1 expert 2 ratio: 0.3289\n",
      "layer 1 expert 3 ratio: 0.2041\n",
      "layer 1 expert 4 ratio: 0.2579\n",
      "layer 1 expert 5 ratio: 0.3045\n",
      "layer 1 expert 6 ratio: 0.2671\n",
      "layer 1 expert 7 ratio: 0.2597\n",
      "layer 2 expert 0 ratio: 0.2771\n",
      "layer 2 expert 1 ratio: 0.3376\n",
      "layer 2 expert 2 ratio: 0.3007\n",
      "layer 2 expert 3 ratio: 0.3835\n",
      "layer 2 expert 4 ratio: 0.2107\n",
      "layer 2 expert 5 ratio: 0.2586\n",
      "layer 2 expert 6 ratio: 0.2419\n",
      "layer 2 expert 7 ratio: 0.2551\n",
      "layer 3 expert 0 ratio: 0.4189\n",
      "layer 3 expert 1 ratio: 0.2152\n",
      "layer 3 expert 2 ratio: 0.4159\n",
      "layer 3 expert 3 ratio: 0.2700\n",
      "layer 3 expert 4 ratio: 0.2748\n",
      "layer 3 expert 5 ratio: 0.2765\n",
      "layer 3 expert 6 ratio: 0.2474\n",
      "layer 3 expert 7 ratio: 0.3301\n",
      "layer 4 expert 0 ratio: 0.3405\n",
      "layer 4 expert 1 ratio: 0.2363\n",
      "layer 4 expert 2 ratio: 0.2543\n",
      "layer 4 expert 3 ratio: 0.3402\n",
      "layer 4 expert 4 ratio: 0.2503\n",
      "layer 4 expert 5 ratio: 0.3217\n",
      "layer 4 expert 6 ratio: 0.2301\n",
      "layer 4 expert 7 ratio: 0.3044\n",
      "layer 5 expert 0 ratio: 0.2178\n",
      "layer 5 expert 1 ratio: 0.2574\n",
      "layer 5 expert 2 ratio: 0.2275\n",
      "layer 5 expert 3 ratio: 0.2411\n",
      "layer 5 expert 4 ratio: 0.3242\n",
      "layer 5 expert 5 ratio: 0.3035\n",
      "layer 5 expert 6 ratio: 0.2181\n",
      "layer 5 expert 7 ratio: 0.2769\n",
      "layer 6 expert 0 ratio: 0.2409\n",
      "layer 6 expert 1 ratio: 0.2253\n",
      "layer 6 expert 2 ratio: 0.3049\n",
      "layer 6 expert 3 ratio: 0.2363\n",
      "layer 6 expert 4 ratio: 0.2952\n",
      "layer 6 expert 5 ratio: 0.2660\n",
      "layer 6 expert 6 ratio: 0.2106\n",
      "layer 6 expert 7 ratio: 0.2283\n",
      "layer 7 expert 0 ratio: 0.2190\n",
      "layer 7 expert 1 ratio: 0.2776\n",
      "layer 7 expert 2 ratio: 0.2150\n",
      "layer 7 expert 3 ratio: 0.2358\n",
      "layer 7 expert 4 ratio: 0.2288\n",
      "layer 7 expert 5 ratio: 0.2202\n",
      "layer 7 expert 6 ratio: 0.3143\n",
      "layer 7 expert 7 ratio: 0.2065\n",
      "layer 8 expert 0 ratio: 0.2189\n",
      "layer 8 expert 1 ratio: 0.2257\n",
      "layer 8 expert 2 ratio: 0.3113\n",
      "layer 8 expert 3 ratio: 0.2275\n",
      "layer 8 expert 4 ratio: 0.2974\n",
      "layer 8 expert 5 ratio: 0.2792\n",
      "layer 8 expert 6 ratio: 0.2164\n",
      "layer 8 expert 7 ratio: 0.2172\n",
      "layer 9 expert 0 ratio: 0.2092\n",
      "layer 9 expert 1 ratio: 0.2168\n",
      "layer 9 expert 2 ratio: 0.2168\n",
      "layer 9 expert 3 ratio: 0.2258\n",
      "layer 9 expert 4 ratio: 0.2533\n",
      "layer 9 expert 5 ratio: 0.2921\n",
      "layer 9 expert 6 ratio: 0.3247\n",
      "layer 9 expert 7 ratio: 0.2168\n",
      "layer 10 expert 0 ratio: 0.3244\n",
      "layer 10 expert 1 ratio: 0.2187\n",
      "layer 10 expert 2 ratio: 0.3147\n",
      "layer 10 expert 3 ratio: 0.2144\n",
      "layer 10 expert 4 ratio: 0.2143\n",
      "layer 10 expert 5 ratio: 0.2179\n",
      "layer 10 expert 6 ratio: 0.2072\n",
      "layer 10 expert 7 ratio: 0.2189\n",
      "layer 11 expert 0 ratio: 0.2181\n",
      "layer 11 expert 1 ratio: 0.2271\n",
      "layer 11 expert 2 ratio: 0.2223\n",
      "layer 11 expert 3 ratio: 0.1913\n",
      "layer 11 expert 4 ratio: 0.3715\n",
      "layer 11 expert 5 ratio: 0.2036\n",
      "layer 11 expert 6 ratio: 0.3398\n",
      "layer 11 expert 7 ratio: 0.2165\n",
      "layer 12 expert 0 ratio: 0.3194\n",
      "layer 12 expert 1 ratio: 0.2204\n",
      "layer 12 expert 2 ratio: 0.2171\n",
      "layer 12 expert 3 ratio: 0.2438\n",
      "layer 12 expert 4 ratio: 0.3368\n",
      "layer 12 expert 5 ratio: 0.2111\n",
      "layer 12 expert 6 ratio: 0.2174\n",
      "layer 12 expert 7 ratio: 0.1950\n",
      "layer 13 expert 0 ratio: 0.2116\n",
      "layer 13 expert 1 ratio: 0.2307\n",
      "layer 13 expert 2 ratio: 0.3090\n",
      "layer 13 expert 3 ratio: 0.2029\n",
      "layer 13 expert 4 ratio: 0.2118\n",
      "layer 13 expert 5 ratio: 0.2075\n",
      "layer 13 expert 6 ratio: 0.2705\n",
      "layer 13 expert 7 ratio: 0.3097\n",
      "layer 14 expert 0 ratio: 0.2184\n",
      "layer 14 expert 1 ratio: 0.2240\n",
      "layer 14 expert 2 ratio: 0.2155\n",
      "layer 14 expert 3 ratio: 0.2115\n",
      "layer 14 expert 4 ratio: 0.2269\n",
      "layer 14 expert 5 ratio: 0.2228\n",
      "layer 14 expert 6 ratio: 0.3173\n",
      "layer 14 expert 7 ratio: 0.3288\n",
      "layer 15 expert 0 ratio: 0.2564\n",
      "layer 15 expert 1 ratio: 0.2573\n",
      "layer 15 expert 2 ratio: 0.2142\n",
      "layer 15 expert 3 ratio: 0.2156\n",
      "layer 15 expert 4 ratio: 0.2776\n",
      "layer 15 expert 5 ratio: 0.2331\n",
      "layer 15 expert 6 ratio: 0.2168\n",
      "layer 15 expert 7 ratio: 0.2384\n",
      "layer 16 expert 0 ratio: 0.2347\n",
      "layer 16 expert 1 ratio: 0.2079\n",
      "layer 16 expert 2 ratio: 0.2330\n",
      "layer 16 expert 3 ratio: 0.2412\n",
      "layer 16 expert 4 ratio: 0.2136\n",
      "layer 16 expert 5 ratio: 0.2189\n",
      "layer 16 expert 6 ratio: 0.2531\n",
      "layer 16 expert 7 ratio: 0.2348\n",
      "layer 17 expert 0 ratio: 0.1946\n",
      "layer 17 expert 1 ratio: 0.2102\n",
      "layer 17 expert 2 ratio: 0.2102\n",
      "layer 17 expert 3 ratio: 0.2337\n",
      "layer 17 expert 4 ratio: 0.2129\n",
      "layer 17 expert 5 ratio: 0.2594\n",
      "layer 17 expert 6 ratio: 0.2687\n",
      "layer 17 expert 7 ratio: 0.2188\n",
      "layer 18 expert 0 ratio: 0.2164\n",
      "layer 18 expert 1 ratio: 0.2160\n",
      "layer 18 expert 2 ratio: 0.2100\n",
      "layer 18 expert 3 ratio: 0.2151\n",
      "layer 18 expert 4 ratio: 0.2480\n",
      "layer 18 expert 5 ratio: 0.2809\n",
      "layer 18 expert 6 ratio: 0.2102\n",
      "layer 18 expert 7 ratio: 0.2487\n",
      "layer 19 expert 0 ratio: 0.2240\n",
      "layer 19 expert 1 ratio: 0.2176\n",
      "layer 19 expert 2 ratio: 0.2184\n",
      "layer 19 expert 3 ratio: 0.2010\n",
      "layer 19 expert 4 ratio: 0.2467\n",
      "layer 19 expert 5 ratio: 0.2376\n",
      "layer 19 expert 6 ratio: 0.2064\n",
      "layer 19 expert 7 ratio: 0.1985\n",
      "layer 20 expert 0 ratio: 0.2105\n",
      "layer 20 expert 1 ratio: 0.2321\n",
      "layer 20 expert 2 ratio: 0.2007\n",
      "layer 20 expert 3 ratio: 0.1753\n",
      "layer 20 expert 4 ratio: 0.2297\n",
      "layer 20 expert 5 ratio: 0.2223\n",
      "layer 20 expert 6 ratio: 0.2114\n",
      "layer 20 expert 7 ratio: 0.2004\n",
      "layer 21 expert 0 ratio: 0.2002\n",
      "layer 21 expert 1 ratio: 0.2269\n",
      "layer 21 expert 2 ratio: 0.2171\n",
      "layer 21 expert 3 ratio: 0.1993\n",
      "layer 21 expert 4 ratio: 0.1857\n",
      "layer 21 expert 5 ratio: 0.1940\n",
      "layer 21 expert 6 ratio: 0.2040\n",
      "layer 21 expert 7 ratio: 0.2209\n",
      "layer 22 expert 0 ratio: 0.1994\n",
      "layer 22 expert 1 ratio: 0.1959\n",
      "layer 22 expert 2 ratio: 0.2221\n",
      "layer 22 expert 3 ratio: 0.2023\n",
      "layer 22 expert 4 ratio: 0.1742\n",
      "layer 22 expert 5 ratio: 0.2384\n",
      "layer 22 expert 6 ratio: 0.2335\n",
      "layer 22 expert 7 ratio: 0.2107\n",
      "layer 23 expert 0 ratio: 0.1958\n",
      "layer 23 expert 1 ratio: 0.2027\n",
      "layer 23 expert 2 ratio: 0.1784\n",
      "layer 23 expert 3 ratio: 0.2554\n",
      "layer 23 expert 4 ratio: 0.2540\n",
      "layer 23 expert 5 ratio: 0.1687\n",
      "layer 23 expert 6 ratio: 0.2408\n",
      "layer 23 expert 7 ratio: 0.1940\n",
      "layer 24 expert 0 ratio: 0.1930\n",
      "layer 24 expert 1 ratio: 0.2153\n",
      "layer 24 expert 2 ratio: 0.2148\n",
      "layer 24 expert 3 ratio: 0.1760\n",
      "layer 24 expert 4 ratio: 0.1953\n",
      "layer 24 expert 5 ratio: 0.1922\n",
      "layer 24 expert 6 ratio: 0.1908\n",
      "layer 24 expert 7 ratio: 0.2281\n",
      "layer 25 expert 0 ratio: 0.1704\n",
      "layer 25 expert 1 ratio: 0.1996\n",
      "layer 25 expert 2 ratio: 0.2137\n",
      "layer 25 expert 3 ratio: 0.1865\n",
      "layer 25 expert 4 ratio: 0.2217\n",
      "layer 25 expert 5 ratio: 0.2493\n",
      "layer 25 expert 6 ratio: 0.1653\n",
      "layer 25 expert 7 ratio: 0.1868\n",
      "layer 26 expert 0 ratio: 0.1743\n",
      "layer 26 expert 1 ratio: 0.1961\n",
      "layer 26 expert 2 ratio: 0.1621\n",
      "layer 26 expert 3 ratio: 0.2445\n",
      "layer 26 expert 4 ratio: 0.1693\n",
      "layer 26 expert 5 ratio: 0.1810\n",
      "layer 26 expert 6 ratio: 0.1691\n",
      "layer 26 expert 7 ratio: 0.2555\n",
      "layer 27 expert 0 ratio: 0.1838\n",
      "layer 27 expert 1 ratio: 0.2185\n",
      "layer 27 expert 2 ratio: 0.2059\n",
      "layer 27 expert 3 ratio: 0.1689\n",
      "layer 27 expert 4 ratio: 0.1655\n",
      "layer 27 expert 5 ratio: 0.2426\n",
      "layer 27 expert 6 ratio: 0.2067\n",
      "layer 27 expert 7 ratio: 0.1990\n",
      "layer 28 expert 0 ratio: 0.1703\n",
      "layer 28 expert 1 ratio: 0.2038\n",
      "layer 28 expert 2 ratio: 0.2202\n",
      "layer 28 expert 3 ratio: 0.1879\n",
      "layer 28 expert 4 ratio: 0.1976\n",
      "layer 28 expert 5 ratio: 0.1858\n",
      "layer 28 expert 6 ratio: 0.2517\n",
      "layer 28 expert 7 ratio: 0.1832\n",
      "layer 29 expert 0 ratio: 0.2214\n",
      "layer 29 expert 1 ratio: 0.2242\n",
      "layer 29 expert 2 ratio: 0.1930\n",
      "layer 29 expert 3 ratio: 0.2321\n",
      "layer 29 expert 4 ratio: 0.1914\n",
      "layer 29 expert 5 ratio: 0.1750\n",
      "layer 29 expert 6 ratio: 0.1914\n",
      "layer 29 expert 7 ratio: 0.1571\n",
      "layer 30 expert 0 ratio: 0.2092\n",
      "layer 30 expert 1 ratio: 0.2695\n",
      "layer 30 expert 2 ratio: 0.2463\n",
      "layer 30 expert 3 ratio: 0.2304\n",
      "layer 30 expert 4 ratio: 0.2782\n",
      "layer 30 expert 5 ratio: 0.2053\n",
      "layer 30 expert 6 ratio: 0.1911\n",
      "layer 30 expert 7 ratio: 0.1769\n",
      "layer 31 expert 0 ratio: 0.2159\n",
      "layer 31 expert 1 ratio: 0.2531\n",
      "layer 31 expert 2 ratio: 0.2226\n",
      "layer 31 expert 3 ratio: 0.2229\n",
      "layer 31 expert 4 ratio: 0.2317\n",
      "layer 31 expert 5 ratio: 0.2968\n",
      "layer 31 expert 6 ratio: 0.2384\n",
      "layer 31 expert 7 ratio: 0.3056\n"
     ]
    }
   ],
   "source": [
    "for layerid in range(32):\n",
    "    for expertid in range(8):\n",
    "        llm.model.layers[layerid].block_sparse_moe.experts[expertid].print_ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_ENDPOINT\"]=\"https://hf-mirror.com\"\n",
    "\n",
    "\n",
    "import lm_eval\n",
    "from lm_eval.models.huggingface import HFLM\n",
    "from lm_eval import evaluator\n",
    "del dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03:13:11:00,185 WARNING  [huggingface.py:121] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2025-01-03:13:11:00,251 WARNING  [huggingface.py:349] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "2025-01-03:13:11:00,259 INFO     [evaluator.py:152] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2025-01-03:13:11:00,261 INFO     [evaluator.py:203] Using pre-initialized model\n",
      "Using the latest cached version of the module from /home/lz/.cache/huggingface/modules/datasets_modules/datasets/winogrande/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2 (last modified on Thu Jan  2 22:35:53 2025) since it couldn't be found locally at winogrande, or remotely on the Hugging Face Hub.\n",
      "2025-01-03:13:13:13,531 WARNING  [load.py:1407] Using the latest cached version of the module from /home/lz/.cache/huggingface/modules/datasets_modules/datasets/winogrande/a826c3d3506aefe0e9e9390dcb53271070536586bab95849876b2c1743df56e2 (last modified on Thu Jan  2 22:35:53 2025) since it couldn't be found locally at winogrande, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(task_name_list, model, tokenizer, num_fewshot, device):\n",
    "    hflm = HFLM(pretrained=llm, tokenizer=tokenizer)\n",
    "    results = evaluator.simple_evaluate(\n",
    "    model=hflm,\n",
    "    tasks=task_name_list,\n",
    "    num_fewshot=num_fewshot)\n",
    "    print(results['results'])\n",
    "\n",
    "\n",
    "\n",
    "# triviaqa\n",
    "task_list=['winogrande','sciq','openbookqa','arc_challenge','arc_easy']\n",
    "# 'boolq',\n",
    "# task_list=['truthfulqa_gen','triviaqa_gen']\n",
    "evaluate(task_list, llm, tokenizer, 0, \"cuda\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
