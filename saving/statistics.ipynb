{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model path: /mnt/storage/zyx/Meta-Llama-3-8B \n",
      "dataset path: /home/lz/workspace/llama2-7b/HQQ/notebooks/draft \n",
      "save path: /home/lz/workspace/llama2-7b/on_the_fly_moe/saving/threshold/chess\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c15bc6e577b479c923bc1bab1a694a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with sparsity of 0\n",
      "profile mode is False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from modeling_llama_up import set_profile_mode\n",
    "import os\n",
    "import csv\n",
    "from utils import get_c4_data, get_model, set_seed\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "### from path.json read paths of model and dataset\n",
    "model_name = \"Llama3-8b\"\n",
    "dataset_name = \"c4\"\n",
    "with open('../path.json', 'r') as file:\n",
    "    paths = json.load(file)\n",
    "    model_path = paths.get(model_name, '')\n",
    "    dataset_path = paths.get(dataset_name, '')\n",
    "    save_path = paths.get('threshold_up_new','')\n",
    "    print('model path:', model_path, '\\ndataset path:', dataset_path, '\\nsave path:', save_path)\n",
    "\n",
    "set_seed(42)\n",
    "# c4data = get_c4_data(model_path, dataset_path, sample_num = 400)\n",
    "model = get_model(model_path)\n",
    "set_profile_mode(mode = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "raw_datasets = load_dataset(dataset_path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "def process(example):\n",
    "    ids = tokenizer.encode(example['text'])\n",
    "    out = {'ids': ids, 'len': len(ids)}\n",
    "    return out\n",
    "\n",
    "tokenized = raw_datasets.map(process, desc='tokenizing raw datasets', num_proc=64)\n",
    "import numpy as np\n",
    "datasets = dict()\n",
    "\n",
    "for split, dset in tokenized.items():\n",
    "    datasets[split] = []\n",
    "    length = np.sum(dset['len'])\n",
    "    datasets[split] = np.ndarray((length, ), np.uint32)\n",
    "    idx = 0\n",
    "    for row in dset:\n",
    "        datasets[split][idx:idx + row['len']] = row['ids']\n",
    "        idx += row['len']\n",
    "torch.save(datasets, 'datasets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = torch.load('./saving/threshold/chess/datasets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_size, block_size):\n",
    "    start_idxs = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in start_idxs])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in start_idxs])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n",
      "8\n",
      "12\n",
      "16\n",
      "20\n",
      "24\n",
      "28\n",
      "32\n",
      "36\n",
      "40\n",
      "44\n",
      "48\n",
      "52\n",
      "56\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "sparsity_level = 0.7\n",
    "# device = 'cuda:1'\n",
    "device_2 = 'cpu'\n",
    "avg_loss = 0.0\n",
    "n_batch = 64\n",
    "accum_steps = 4\n",
    "batch_size = 1\n",
    "block_size = 2048\n",
    "torch.manual_seed(42)\n",
    "\n",
    "gate_proj_states_thresholds = [torch.zeros([1,]) for _ in range(len(model.model.layers))]\n",
    "up_proj_states_mean_squares = [torch.zeros(model.config.intermediate_size) for _ in range(len(model.model.layers))]\n",
    "attention_inputs_thresholds = [torch.zeros([1,]) for _ in range(len(model.model.layers))]\n",
    "attention_outputs_thresholds = [torch.zeros([1,]) for _ in range(len(model.model.layers))]\n",
    "\n",
    "gate_proj_states = [torch.zeros([accum_steps * batch_size * block_size, model.config.intermediate_size]) for _ in range(len(model.model.layers))]\n",
    "up_proj_states = [torch.zeros([accum_steps * batch_size * block_size, model.config.intermediate_size]) for _ in range(len(model.model.layers))]\n",
    "attention_input_states = [torch.zeros([accum_steps * batch_size * block_size, model.config.hidden_size]) for _ in range(len(model.model.layers))]\n",
    "attention_output_states = [torch.zeros([accum_steps * batch_size * block_size, model.config.hidden_size]) for _ in range(len(model.model.layers))]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(n_batch // accum_steps):\n",
    "        print(step * accum_steps)\n",
    "        for batch_idx in range(accum_steps):\n",
    "            inputs, labels = get_batch(datasets['validation'], batch_size, block_size)\n",
    "            inputs = inputs.cuda()\n",
    "            outputs = model(inputs, labels=inputs)\n",
    "            avg_loss = avg_loss + outputs.loss / n_batch\n",
    "\n",
    "            for layer_idx in range(len(model.model.layers)):\n",
    "                ### gate/up换个位置\n",
    "                # states = model.model.layers[layer_idx].mlp.gate_proj_states\n",
    "                states = model.model.layers[layer_idx].mlp.up_proj_states\n",
    "                gate_proj_states[layer_idx][batch_idx * batch_size * block_size : (batch_idx + 1) * batch_size * block_size, :] = states.reshape(-1, states.size(-1))\n",
    "\n",
    "                # states = model.model.layers[layer_idx].mlp.up_proj_states\n",
    "                states = model.model.layers[layer_idx].mlp.gate_proj_states\n",
    "                up_proj_states[layer_idx][batch_idx * batch_size * block_size : (batch_idx + 1) * batch_size * block_size, :] = states.reshape(-1, states.size(-1))\n",
    "\n",
    "                # states = model.model.layers[layer_idx].self_attn.attention_input_states\n",
    "                # attention_input_states[layer_idx][batch_idx * batch_size * block_size : (batch_idx + 1) * batch_size * block_size, :] = states.reshape(-1, states.size(-1))\n",
    "\n",
    "                # states = model.model.layers[layer_idx].self_attn.attention_output_states\n",
    "                # attention_output_states[layer_idx][batch_idx * batch_size * block_size : (batch_idx + 1) * batch_size * block_size, :] = states.reshape(-1, states.size(-1))\n",
    "        \n",
    "        for layer_idx in range(len(model.model.layers)):   \n",
    "            gate_proj_states_thresholds[layer_idx] += gate_proj_states[layer_idx].to(device_2).abs().flatten().kthvalue(int(gate_proj_states[layer_idx].numel() * sparsity_level)).values.to('cpu')\n",
    "\n",
    "            # attention_inputs_thresholds[layer_idx] += attention_input_states[layer_idx].to(device_2).abs().flatten().kthvalue(int(attention_input_states[layer_idx].numel() * sparsity_level)).values.to('cpu')\n",
    "\n",
    "            # attention_outputs_thresholds[layer_idx] += attention_output_states[layer_idx].to(device_2).abs().flatten().kthvalue(int(attention_output_states[layer_idx].numel() * sparsity_level)).values.to('cpu')\n",
    "            \n",
    "            up_proj_states_mean_squares[layer_idx] += (torch.sum(up_proj_states[layer_idx].to(device_2) ** 2, dim=0).to('cpu') / up_proj_states[layer_idx].size(0)).to('cpu')\n",
    "\n",
    "for layer_idx in range(len(model.model.layers)):\n",
    "    gate_proj_states_thresholds[layer_idx] /= n_batch // accum_steps\n",
    "    # attention_inputs_thresholds[layer_idx] /= n_batch // accum_steps\n",
    "    # attention_outputs_thresholds[layer_idx] /= n_batch // accum_steps\n",
    "    up_proj_states_mean_squares[layer_idx] /= n_batch // accum_steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n",
      "8\n",
      "12\n",
      "16\n",
      "20\n",
      "24\n",
      "28\n",
      "32\n",
      "36\n",
      "40\n",
      "44\n",
      "48\n",
      "52\n",
      "56\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "importance_thresholds = [torch.zeros([1,]) for _ in range(len(model.model.layers))]\n",
    "gate_proj_states_thresholds_2 = [torch.zeros(model.config.intermediate_size) for _ in range(len(model.model.layers))]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step in range(n_batch // accum_steps):\n",
    "        print(step * accum_steps)\n",
    "        for batch_idx in range(accum_steps):\n",
    "            inputs, labels = get_batch(datasets['validation'], batch_size, block_size)\n",
    "            inputs = inputs.cuda()\n",
    "            outputs = model(inputs, labels=inputs)\n",
    "            avg_loss = avg_loss + outputs.loss / n_batch\n",
    "\n",
    "            for layer_idx in range(len(model.model.layers)):\n",
    "                # states = model.model.layers[layer_idx].mlp.gate_proj_states\n",
    "                states = model.model.layers[layer_idx].mlp.up_proj_states\n",
    "                gate_proj_states[layer_idx][batch_idx * batch_size * block_size : (batch_idx + 1) * batch_size * block_size, :] = states.reshape(-1, states.size(-1))\n",
    "        \n",
    "        for layer_idx in range(len(model.model.layers)):   \n",
    "            importance_scores = gate_proj_states[layer_idx] ** 2 * up_proj_states_mean_squares[layer_idx]\n",
    "            importance_thresholds[layer_idx] += importance_scores.to(device_2).flatten().kthvalue(int(importance_scores.numel() * sparsity_level)).values.to('cpu')\n",
    "\n",
    "for layer_idx in range(len(model.model.layers)):\n",
    "    importance_thresholds[layer_idx] /= n_batch // accum_steps\n",
    "    gate_proj_states_thresholds_2[layer_idx] = (importance_thresholds[layer_idx].expand_as(gate_proj_states_thresholds_2[layer_idx]) / up_proj_states_mean_squares[layer_idx]) ** 0.5\n",
    "\n",
    "thresholds = {'up_proj_states_thresholds': gate_proj_states_thresholds, 'up_proj_states_thresholds_2': gate_proj_states_thresholds_2}\n",
    "\n",
    "with open('path.json', 'r') as file:\n",
    "    paths = json.load(file)\n",
    "    save_path = paths.get('threshold_up_new','')\n",
    "    print('save path:', save_path)\n",
    "torch.save(thresholds, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0.0430, 0.0532, 0.0464,  ..., 0.0520, 0.0472, 0.0433]), tensor([0.0546, 0.0589, 0.0626,  ..., 0.0616, 0.0647, 0.0532]), tensor([0.0695, 0.0710, 0.0788,  ..., 0.0764, 0.0781, 0.0753]), tensor([0.1077, 0.1176, 0.1157,  ..., 0.1057, 0.1080, 0.1078]), tensor([0.1757, 0.1625, 0.1389,  ..., 0.1653, 0.1647, 0.1757]), tensor([0.1111, 0.1100, 0.1518,  ..., 0.1844, 0.1667, 0.1718]), tensor([0.1231, 0.1730, 0.1974,  ..., 0.1832, 0.1677, 0.1704]), tensor([0.1086, 0.1731, 0.0501,  ..., 0.1701, 0.1229, 0.1641]), tensor([0.1794, 0.2142, 0.1114,  ..., 0.2115, 0.1843, 0.1764]), tensor([0.1431, 0.1840, 0.1670,  ..., 0.1544, 0.1965, 0.1978]), tensor([0.1780, 0.1699, 0.1990,  ..., 0.1513, 0.1691, 0.1669]), tensor([0.1339, 0.1460, 0.2050,  ..., 0.1584, 0.1386, 0.1630]), tensor([0.1705, 0.1448, 0.1696,  ..., 0.2083, 0.1902, 0.2003]), tensor([0.2199, 0.1668, 0.1999,  ..., 0.1858, 0.1896, 0.1733]), tensor([0.1939, 0.2284, 0.1840,  ..., 0.1795, 0.2215, 0.2305]), tensor([0.2053, 0.2025, 0.2201,  ..., 0.1929, 0.2071, 0.2386]), tensor([0.2201, 0.2928, 0.2279,  ..., 0.2021, 0.2231, 0.1925]), tensor([0.1551, 0.2172, 0.2200,  ..., 0.2379, 0.2285, 0.2427]), tensor([0.1995, 0.2069, 0.2222,  ..., 0.2432, 0.2174, 0.2272]), tensor([0.1881, 0.2192, 0.1722,  ..., 0.2180, 0.1853, 0.2264]), tensor([0.2299, 0.1249, 0.2001,  ..., 0.1835, 0.2127, 0.1514]), tensor([0.2318, 0.2358, 0.2241,  ..., 0.2271, 0.2432, 0.2291]), tensor([0.2172, 0.2189, 0.2357,  ..., 0.2219, 0.2017, 0.1977]), tensor([0.2163, 0.2173, 0.2275,  ..., 0.2138, 0.2200, 0.2251]), tensor([0.2312, 0.2293, 0.2192,  ..., 0.2367, 0.2302, 0.2048]), tensor([0.2079, 0.2126, 0.2228,  ..., 0.2130, 0.2202, 0.2262]), tensor([0.2295, 0.2238, 0.2449,  ..., 0.2265, 0.2299, 0.2290]), tensor([0.1515, 0.2361, 0.2045,  ..., 0.2462, 0.2376, 0.2337]), tensor([0.2361, 0.2520, 0.1538,  ..., 0.2663, 0.0640, 0.2484]), tensor([0.2081, 0.2571, 0.2639,  ..., 0.2662, 0.2348, 0.2474]), tensor([0.2654, 0.2520, 0.2813,  ..., 0.3352, 0.2677, 0.2574]), tensor([0.3523, 0.3825, 0.3498,  ..., 0.2754, 0.3501, 0.1057])]\n"
     ]
    }
   ],
   "source": [
    "print(thresholds[\"gate_proj_states_thresholds_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt2 = torch.load('./threshold/chess/thresholds_0_7.pt')[\"gate_proj_states_thresholds_2\"]\n",
    "pt2[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
